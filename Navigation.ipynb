{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import heapq\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BananaBrain\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "print(brain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. DQN with Prioritized Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>priority exponent</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment boundaries</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "priority exponent   0.00   0.25   0.50   0.75  1.00\n",
       "segment boundaries                                 \n",
       "0                    0.0  0.000  0.000  0.000  0.00\n",
       "1                    0.2  0.134  0.089  0.060  0.04\n",
       "2                    0.4  0.318  0.253  0.201  0.16\n",
       "3                    0.6  0.528  0.465  0.409  0.36\n",
       "4                    0.8  0.757  0.716  0.677  0.64\n",
       "5                    1.0  1.000  1.000  1.000  1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_priority_segments(num_segments, priority_exp):\n",
    "    return [(i / num_segments) ** (priority_exp + 1) for i in range(num_segments + 1)]\n",
    " \n",
    "def demo_compute_priority_segments():\n",
    "    priority_exps = [0, 0.25, 0.5, 0.75, 1]\n",
    "    segments = {e: compute_priority_segments(5, e) for e in priority_exps}\n",
    "    \n",
    "    df = pd.DataFrame(segments)\n",
    "    df.columns.name = 'priority exponent'\n",
    "    df.index.name = 'segment boundaries'\n",
    "    pd.set_option('precision', 3)\n",
    "    display(df)\n",
    "        \n",
    "demo_compute_priority_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>priority exponent</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "priority exponent  0.00   0.25   0.50   0.75   0.99\n",
       "rank                                               \n",
       "1                  0.01  0.024  0.056  0.116  0.212\n",
       "20                 0.01  0.012  0.012  0.012  0.011\n",
       "40                 0.01  0.010  0.009  0.007  0.006\n",
       "60                 0.01  0.009  0.007  0.005  0.004\n",
       "80                 0.01  0.008  0.006  0.004  0.003\n",
       "100                0.01  0.008  0.006  0.004  0.002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_rank_probs(ranks, memory_size, priority_exp):\n",
    "    return (1 - priority_exp) / ranks**priority_exp / (memory_size**(1 - priority_exp) - 1)\n",
    "\n",
    "def demo_compute_rank_probs():\n",
    "    ranks = np.array([1, 20, 40, 60, 80, 100])\n",
    "    priority_exps = [0, 0.25, 0.5, 0.75, 0.99]\n",
    "    rank_probs = {e: compute_rank_probs(ranks, 100, e) for e in priority_exps}\n",
    "    \n",
    "    df = pd.DataFrame(rank_probs, index=ranks)\n",
    "    df.columns.name = 'priority exponent'\n",
    "    df.index.name = 'rank'\n",
    "    pd.set_option('precision', 3)\n",
    "    display(df)\n",
    "\n",
    "demo_compute_rank_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sample exponent</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sample exponent  0.00   0.25   0.50   0.75   1.00\n",
       "rank                                             \n",
       "1                 1.0  0.562  0.316  0.178  0.100\n",
       "20                1.0  0.818  0.669  0.547  0.447\n",
       "40                1.0  0.892  0.795  0.709  0.632\n",
       "60                1.0  0.938  0.880  0.826  0.775\n",
       "80                1.0  0.972  0.946  0.920  0.894\n",
       "100               1.0  1.000  1.000  1.000  1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_sample_weights(sample_probs, memory_size, priority_exp, sample_exp):\n",
    "    min_sample_prob = compute_rank_probs(memory_size, memory_size, priority_exp)\n",
    "    max_sample_weight = (memory_size * min_sample_prob)**(-sample_exp)\n",
    "    sample_weights = (memory_size * sample_probs)**(-sample_exp) / max_sample_weight\n",
    "    return sample_weights\n",
    "    \n",
    "def demo_compute_sample_weights():\n",
    "    memory_size = 100\n",
    "    priority_exp = 0.5\n",
    "    ranks = np.array([1, 20, 40, 60, 80, 100])\n",
    "    sample_exps = [0, 0.25, 0.5, 0.75, 1]\n",
    "    sample_probs = compute_rank_probs(ranks, memory_size, priority_exp)\n",
    "    sample_weights = {e: compute_sample_weights(sample_probs, memory_size, priority_exp, e) for e in sample_exps}\n",
    "\n",
    "    df = pd.DataFrame(sample_weights, index=ranks)\n",
    "    df.index.name = 'rank'\n",
    "    df.columns.name = 'sample exponent'\n",
    "    pd.set_option('precision', 3)\n",
    "    display(df)\n",
    "\n",
    "demo_compute_sample_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>996</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>985</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>948</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>908</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>716</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   error  weight\n",
       "0    996   0.447\n",
       "1    985   0.548\n",
       "2    948   0.642\n",
       "3    908   0.707\n",
       "4    846   0.752\n",
       "5    716   0.819\n",
       "6     46   0.857\n",
       "7     37   0.891\n",
       "8     19   0.949\n",
       "9     12   0.969"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PriorityReplayMemory:\n",
    "    def __init__(self, memory_size, batch_size, priority_exp, sort_every):\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.priority_exp = priority_exp\n",
    "        self.sort_every = sort_every\n",
    "        \n",
    "        self.heap = []\n",
    "        self.step = 0\n",
    "        \n",
    "        self.segments = compute_priority_segments(batch_size, priority_exp)\n",
    "        self.counter = itertools.count() \n",
    "    \n",
    "    def add(self, experience, error=None):\n",
    "        if error:\n",
    "            priority = -error\n",
    "        else:\n",
    "            if len(self.heap) > 0:\n",
    "                priority = self.heap[0][0]\n",
    "            else:\n",
    "                priority = -10\n",
    "                \n",
    "        count = next(self.counter)\n",
    "        heapq.heappush(self.heap, (priority, count, experience))\n",
    "        \n",
    "        if len(self.heap) > self.memory_size:\n",
    "            self.heap.pop()\n",
    "            \n",
    "        self.step = (self.step + 1) % self.sort_every\n",
    "        \n",
    "        if self.step == 0:\n",
    "            self.heap.sort(key=lambda x: x[0])\n",
    "            \n",
    "    \n",
    "    def sample(self, sample_exp, log=False):\n",
    "        size = len(self.heap)\n",
    "\n",
    "        # Scale segements to the number of experiences\n",
    "        segments = [(math.ceil(start * (size - 1)), math.floor(end * (size - 1)))\n",
    "                    for start, end in zip(self.segments[:-1], self.segments[1:])]\n",
    "        \n",
    "        # Check if the first (smallest) segment contains more than one experience\n",
    "        if segments[0][0] < segments[0][1]:\n",
    "            indexes = [random.randint(start, end) for start, end in segments]\n",
    "        else: # Ignore segments, do uniform sampling\n",
    "            indexes = random.sample(range(size), self.batch_size)\n",
    "            \n",
    "        # Select experiences\n",
    "        experiences = [self.heap[i][2] for i in indexes]\n",
    "        \n",
    "        # Compute importance-sampling weights\n",
    "        ranks = np.array(indexes) + 1\n",
    "        probs = compute_rank_probs(ranks, self.memory_size, self.priority_exp)\n",
    "        weights = compute_sample_weights(probs, self.memory_size, self.priority_exp, sample_exp)\n",
    "            \n",
    "        # Remove sampled experiences\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del self.heap[index]\n",
    "            \n",
    "        heapq.heapify(self.heap)\n",
    "        \n",
    "        return experiences, weights\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.heap)\n",
    "    \n",
    "def demo_priority_replay_memory():\n",
    "    memory = PriorityReplayMemory(memory_size=100, batch_size=10, priority_exp=0.5, sort_every=10)\n",
    "    \n",
    "    for i in range(1000):\n",
    "        memory.add(i, i)\n",
    "\n",
    "    exps, probs = memory.sample(0.5)\n",
    "    df = pd.DataFrame({'error': exps, 'weight': probs})\n",
    "    pd.set_option('precision', 3)\n",
    "    return df\n",
    "    \n",
    "demo_priority_replay_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple('Experience', 'state action reward next_state done')\n",
    "\n",
    "class PriorityReplayAgent:\n",
    "    def __init__(self, \n",
    "                 state_size, \n",
    "                 action_size,\n",
    "                 memory_size,\n",
    "                 batch_size, \n",
    "                 priority_exp,\n",
    "                 sort_every,\n",
    "                 learn_every,\n",
    "                 learn_rate,\n",
    "                 discount_factor,\n",
    "                 soft_update_factor,\n",
    "                 seed):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.priority_exp = priority_exp\n",
    "        self.learn_every = learn_every\n",
    "        self.discount_factor = discount_factor\n",
    "        self.soft_update_factor = soft_update_factor\n",
    "        \n",
    "        random.seed(seed)\n",
    "\n",
    "        self.local_model = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.target_model = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.local_model.parameters(), lr=learn_rate)\n",
    "        self.memory = PriorityReplayMemory(memory_size, batch_size, priority_exp, sort_every)\n",
    "        \n",
    "        self.step = 0\n",
    "    \n",
    "    def perceive(self, state, action, reward, next_state, done, sample_exp, log=False):\n",
    "        experience = Experience(state, action, reward, next_state, done)\n",
    "        self.memory.add(experience)\n",
    "        \n",
    "        self.step = (self.step + 1) % self.learn_every\n",
    "        \n",
    "        if self.step == 0 and len(self.memory) >= self.batch_size:\n",
    "            self.learn(sample_exp, log)\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        self.local_model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action_values = self.local_model(state)\n",
    "        \n",
    "        self.local_model.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > epsilon:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, sample_exp, log):\n",
    "        experiences, sample_weights = self.memory.sample(sample_exp, log)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.target_model(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + self.discount_factor * Q_targets_next * (1 - dones)\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.local_model(states).gather(1, actions)\n",
    "        # Compute TD errors\n",
    "        td_errors = Q_targets - Q_expected\n",
    "        \n",
    "        # Re-add sampled experiences with new priorities\n",
    "        priorities = td_errors.detach().cpu().abs().squeeze().numpy()\n",
    "        \n",
    "        for experience, priority in zip(experiences, priorities):\n",
    "            self.memory.add(experience, priority)\n",
    "        \n",
    "        # Compute loss with importance-sampling weights\n",
    "        sample_weights = torch.from_numpy(sample_weights).float().unsqueeze(1).to(device)\n",
    "        loss = (sample_weights * td_errors**2).mean()\n",
    "\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Soft update of target model: θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        for target_param, local_param in zip(self.target_model.parameters(), self.local_model.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                self.soft_update_factor * local_param.data + (1.0 - self.soft_update_factor) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.69\n",
      "Episode 200\tAverage Score: 3.71\n",
      "Episode 300\tAverage Score: 7.50\n",
      "Episode 400\tAverage Score: 10.30\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXeYJVWZ/7+n6oaOE3sSwwxDHslhBFRAgqIgirAqYNxdXdZVV13XdUf9GdfABmV1lVXEwLoosCiiIkiUJGmAAYY4w8wwOfTM9HS43TdUnd8fVW/VqVOn7r3dfdP0fT/P00/fW7fCqeq+73veeISUEgzDMEz7YjV7AAzDMExzYUXAMAzT5rAiYBiGaXNYETAMw7Q5rAgYhmHaHFYEDMMwbQ4rAoZhmDaHFQHDMEybw4qAYRimzUk1ewDV0NfXJ5csWdLsYTAMw+xTPP744/1SyjmV9tsnFMGSJUuwYsWKZg+DYRhmn0II8Uo1+7FriGEYps1hRcAwDNPmsCJgGIZpc1gRMAzDtDmsCBiGYdqcuikCIcQiIcQ9QojnhBDPCiE+4W+fJYS4Qwix2v89s15jYBiGYSpTT4ugBOAfpZRHADgFwEeFEEcAWA7gLinloQDu8t8zDMMwTaJuikBKuVVK+YT/egjA8wAWArgAwDX+btcAeHu9xsAwTHuzbe8Y7np+e7OH0fI0JEYghFgC4HgAjwCYJ6Xc6n+0DcC8hGMuE0KsEEKs2LlzZyOGyTDMFOPCKx/EB6/hYtRK1F0RCCF6APwKwCellIPqZ1JKCUCajpNSXiWlXCalXDZnTsUKaYZhmBhb9441ewj7BHVVBEKINDwlcK2U8tf+5u1CiAX+5wsA7KjnGBiGYZjy1DNrSAD4MYDnpZTfVj76LYAP+K8/AODmeo2BYRgGADznA5NEPZvOvQ7A+wA8I4RY6W/7HIDLAdwghPgggFcAvKuOY2AYhoErAVs0exStS90UgZTyAQBJj/7sel2XYRhGx7MIWBMkwZXFDMNMedgxVB5WBAzDTHlcjhGUhRUBwzBTHtYD5WFFwDAM0+awImAYZsrDrqHysCJgGGbKw3qgPKwIGIaZ8rAeKA8rAoZhpjzsGioPKwKGYaY8rAfKw4qAYZipDyuCsrAiYBhmylNr11DJcfH8Vq+r/gvbBlF03Mjn2wfHsGOouhbYJcfFn17cgRe2DVbeuU6wImAYZspTa4Pga7c8j3O/cz9Wbd6Lt3z3Afzhma2Rz0/+xl046et3VXWu+1bvxF/+9DGc/90HajzK6mFFwDDMlKfWbajvfclbNXHXSAGOKzGQK074XLtHvGNLbvP8V6wIGIaZ8tRaxg6NecK7WPJcQrpraDzkCqWajGkysCJgGGbKI2vsHBoc84R3rugAAIrOxM+fKzg1GdNkYEXAMMzUp8YWQcG3BMYKpAgmYxF450hZzVsvgRUBwzBTnnq538mtMylFkGfXEMMwTN2ptWuIqIlryD9HM6ufWREwDDPlqaWMzZdCn/5oDVxDdI4mJg2xImAYprb8eU0/rr5/bbOHEaGWs+1dw4XgdS0UwYjiGqp1mmu11G3xeoZh2pN3X/0IAOBDpx3U5JGE1FK+qoK7Fq6h0WJoYbgSsJsQM2aLgGEYZhw4ilahQG8tsoaA5sUJWBEwDDPlqaWAdRRn/mixtq4hVgQMw0wpmuXvNlHLobiKzKfZfKlGrqFmPTJWBAzD1IV8aeKz5FpTS/laUjQBBYsL7BpiGIaJMxnhWGtqKWDVc+VqUVmsuIacJuWQsiJgGKYu5IutowhqOdFWZf5YcXKuISklckUH3RkbQPNqCVgRMAxTMwqKO6iVLAJAQkoZGd9EUWftuUm6hvIlF1IC3Vkvk79ZcRVWBAzD1ITNA6M47P/dGrzPF5vfVZNwJfDvf3wRh/2/W4NZ/ERRFcHIJHsNkSLp8RUBWwQMw+zTvLxjOPK+pYLFErj2kQ0AMHlFoMzaJ+saosBzJuWJYg4WMwyzT+NoQqwWbphaIX3XEDD5eIGrTNuponiiFgElINl+C2pWBAzD7NO4ml+jlSwC1w0VwGSXhDRl9kw0RkDKM2V7opjrCBiG2afRBWTLWQT+68mmaJIi6Uzb4bYJuoZIeabZImAYZiqgCzG1XXOzkTLMyJlMzj8Q3mdXJlQEEz0nKaWUTYpgUkObMHVTBEKInwghdgghVinbviyE2CyEWOn/nFev6zMM01h0l0tLWQQSNbMI6PjOWigCX6mkfdeQ7l5rFPW0CH4G4M2G7VdIKY/zf/5Qx+szDNNAdAHbSjECL1jsvVZbREwEs0UwOdcQrVc85WIEUsr7AOyu1/kZhmktdNdQ61kE3vhuW7UNr+waiXy+Zscw7n5he+y4rXtH8funt0S2UTxAjRGM1yIYGivi+sc2BBaBbbVf+ujHhBBP+66jmUk7CSEuE0KsEEKs2LlzZyPHxzDMBNBlYSvFCFwpA//7f9z+Es7+1r2Rz9/w7Xvx1z9bETvuL678Mz72iycjgp6E92RcQ8t/9Qz++VfP4OmNewEAabu9gsX/DeBgAMcB2ArgW0k7SimvklIuk1IumzNnTqPGxzDMBGm19FF1PLp4TUoh1ZXXlr1jAKLWDZ23Ix11DY2nPcTGPTnvvL4CofTRKRcsNiGl3C6ldKSULoAfATipkddnGKZ+6AVlzVYE6nikRFW9qHePFIzbVUVA5+1I2ZF9xlOfQBXJGV8BpIMYQRtYBEKIBcrbCwGsStqXYZh9C10QNl0RqBaBlGXdLhT47R8yKwL1Xui82XRUfI7HPTTmd2YV/vrElD6qK9NGUbfF64UQvwRwBoA+IcQmAF8CcIYQ4jh4unk9gL+t1/UZhmksumuo2cFiVfBXMghmdmWQK4yifzhv/LxgUARqsBgwZw5JKSFEfDV6WpWMlGeYPlpmkHWkbopASnmpYfOP63U9hmGaS9wiaG6wOGoRlHe7zOxOY/NAVBGo+6v34hhiBIDZInAlYMf1QNCZteQfEyiCdnANMQwzddEFYfMtAvW1rGgRAED/cOgaGlJWDlNdQySss6nKrqEkwT7mn4+sCHuq1hEwDNNeFDXB3+wYgRuzCJL3JaGuWgT9Q+Fr9V5KQYxACxYbXENJVcykJKm4LdVm6aMMw0xRinUMFq/rH8GS5bdgjbbmAQA8uKYfS79wK/aOFiPbI1lDFVKGSGD/+IF1eGB1PwBgl5JBpLqGwvTRqPg0dSCtJNfJIkj7BWUXfP9B3PTkpvIH1QFWBAzD1ATdNeLUMPL525Vede/NKzfHPvve3WswVnSxavPeyHbdIiiHOplftcU7j7qATTRY7P3W00fp/tXYQqUZPlkRKSWQ8KWbny0/2DrAioBhmJqgu4Ym29ytWmhmrq88FqsjKIPrShy/eAaAcPlIdfx5Qx2Bnj5KQl297UrpoEUtWAwAlmWILtcZVgQMw9SEuEVQe0VgEpFZf2auu6IiWUNVuIbSloXOtI2cHyRWZ/NRi8CFbYnAnRPs499/JG21glFUpBiBIvwbrwZYETAMUyP0GEGzLQJ1Ml5pKI4rYVlAd9ZGzj+P6tnKa64h2xJIp6Iimyyi6HWrdQ01VxSzImAYpibEXEM11APlZvSUz0/VusH1tcricjhSwrYEOjM2Rsk1lGARuFLCFiLizgHCbCJ3XDECg0VgKECrN6wIGIapCbprqFGLrFDqp17AFs0aiqK74R1XwhIC3ZkURsg1FIkRRAvKbEsgleAakhViBKqCIitKDRaza4hhmH0W3TU02QVgqoUsAj1G4JaxCCxt1u1KiRRZBMXyFoGnNIBMgmvIrRCkHlVcWEFlsaJUmmAQsCJgmH0NKSWe2LCn2cOIobuGyumBJzbsgZQSa3YMYyBnbvQGAINjRby0fSjcYJCSZBGMFR08s2lvILRVQa73AVIzc57eNICxogPbEujK2BjJl7BpTw5bB8aCffSmcynbSnQNqVcyuYZySsWyKX2UbII9IwXcvHIzdgyOod6wImCYfYwnNuzBRVf+Gc9u2Vt55wYSyxpK8I+/uG0IF135Zzy8djfe8O17cd537k8854/vX4e/+O8/l03/JIG8YXcOb/3eA/jsr5/xru+aZ/QAYPsK5fmtg3jb9x7ES9uHYQmBrkwKuYKDU//1Hnz9D88H+0dcQ9JzI+muoaIha8jkHVMtAn09AiDUdWv7h/GJ61bi+W1DqDd1azrHMEx9GBzzZpTDY6UKezYWvelcUtYQVQAPjnm/afEXE7tG8hgaK5V1M9FVcnlPwN77kreioXqIrgjIIFjXHy5ZaVsCmZQVEdSm4x1HwrbiriHaR00ZNcVJ1OdUCiqL4zECqmfozkQL1+oBWwQMs49B/u5mrWaVhC5skxQBzZyr6d9PwnC0kLwvXYdm7btHvB5BkToAR1cEnrgdyIVtKTzXUAoj+bgi0AvKJpM1pCoHOsaOZA15v2kcnawIGIbRIZnWrAZlSVRbUEb7mZq06VAqZ67gWT+mOCo9hxF/X7psUrAXCGMEA6NhfIJiBKOFuKWlL1Vp28muoWiMID5edVxk6aSVTqbCv8vRojeOrkz9HTesCBhmH8OV8ZlnK6C7hpLGR4HbatpUk3Cn3yZI4YzkowLcLRMjoAn4XtUiEJ4iyGmuoWzKMloESa6hShZBJH20TNYQu4YYhkmEBFyjKnerZbyuoTElAKtXBRM0OzfN0oPrSLMiiASLq3ANWb5rSJfdnRk7cm8lV8KyqnQNGZ5BVBEk1xHk2DXEMEwSJEdazCAYt2toVJnlJy0RSbNik9+eIGE7rCuCyApjZtfQHiV1NeW7hnQ603asDbUtRKwthLnFRHy8TiRYTE3n4pXFdO/sGmIYJgYJuFazCGJZQxVcQ2p2jroymEpOjxEYggR0WVUR5AqlqrKG4hZBkiKI1hHYlogIb+++qus15EZiBL5FYMVFca5YQjZlRQLJ9YIVAcO0CFfc8RIeXbe74n6yTjGCQsnFP9/4NLYMjE7oeL2gbPvgGD79f0/F3D6BRaAqgqGoRXDNn9fjlqe3BgpAjRF8+/YXI8+JFKLaa6h/qFA+WOxrlP6R8Lq2X0eg05mxY0tV2pZARrEIMrYVVFarfxeTsnYMCiriGqIYQd4xKqZ6wIqAYVqE79y1Gu/64UMV93MMAqcWPPhyP65fsRGfu+mZCR2vt5gYK7q48fFN+N1TWyLbyR0ypgj3ES0G8KXfPouP/uIJJX003Pe7d6+JPCfTcxgplILrAMluq5zicrItgWmdBkWgWQQl6jWkKIK0LapuMaHWRDgGi0ANFjfCLQSwImCYfQ6St7X2DNEMN1+snM1jopRQF6APs+C7hnKKcE9KJQ1iBL6iqHZdYMeVESsg1hCP3GuKpLYtgb6ebOxcerCYGtSprqGUbVXvGlKGEriGIsFiihGUGhIoBlgRMMw+R72yhjJ+Lrtp7d1q0GMEAdpmk2so6V6CmXsQK4gHjZP88OosXr8nOq+sRhHowWLfNaSmfKYV11AlRWByWSWljzYidRRgRcAw+xz1qiOgoGQ1Fb8mkmb1+loCgWtIUQTFCp1KSWBSkVVGKcCqziIwt79Qj7WEwMyudOxcXQaLwLZEpHFdJsE1VLmy2DvGNqSPjhYctggYhjHj1EkRkICqptDLRNKsXh+myTVUrXVDaaQdiiJIStFUZ/FJ6ymrx9qWeaUwPVjs+OmjKqprqFLTOb3XkG2JyPoIlD46UihxjIBh2olKK2ipBDGCGrf7H0/Fr/H4hAHpwtDkGtJn7EmQ8qA1CIDkoq1ogNfcGVU9VhfugOemyabMFoFK2hZK1lC4vXJBmQtbiMj6CKpFwFlDDNNGjGdyH8QIamwRhM3bxq8IXFcm3kOSa2g0YhG4sc9NkGtIVQTGVcBiMQKt/YWhX5NtyOX3WklYWhvq6HoGgB8jCK5X3iJQr1l0vLWSIzookjXEioBhpizlqmArQYJkPFaEiXzJwdqdw4FioRn9aNHBWNHBSL5U9TV0a0Bdg1c9RaHkYth374wlWAS7yyxUE1oE5WMErhtVaLprqOS6yBVKWtZQ/HqWJYJeQ1KxIlImReC42D1SwBZlQZtKvYYoA0m3CMaKDrYNjrFriGGmKnc+tx1HfemPeFJZZWw8/v4w0Dm5cfzT/z2Ns751L35431rvfL4w3j1SwNIv3IYjv/TH4LNqx0So6ZDqJ/9041P45aMbAJizhq5/bANO+vpdkXOps2LK+8+mFNeQ4dmVXLdC+ihwxBf/GClCo1n+0vm9wTZbeIVjUoa+/ZIvvInujI20LTBScHDCv9yB9//k0bJji65ZbHANCYF/uH4lAGB6Zzx4XQ9YETBMg3lo7S4AwIr1oSIYz+Se9p1ssJj6++zyf5sWf/n901ti20zoPv5IQzZlnBt254LXo5E6Au/aN68Mr3fh8Qvx0796NY7cb1qwjeoJKloEUgsW0/k/+jq8a9n+xnugGMH1f/savP6wOd42SyDrX4ssDNeVgfVw7z+dgfs+cybStoUhw0JBlXoNSd/NFAkWI/zb/PWpBxrHWmtYETBMgyEhprpGxmUR1ChryFFmuOpvFX2R90rnItT2C+pHaiVvJFhMraQV5XDqIX048/C5kapbcqlFgsVGYRsNelOMYL8ZnVg8q8t4DxQAnt6ZxuG+VWCJ0PpQ10KmfQ+Y3Y3ZPVmk7WgcIRibKVis/d1sSwSZQoAXLyg6Eqcd2scWAcNMVTp8waK2YR5PcZhryHiZCEF1LSkCQ+ZOte3O9ACv6hpS3TK5YknZHvWVA9F201QroGbo0PKcEddQmawhqv4tKl0+TUFh/TqkAC1/+UogXAHNswii50jbwliRXamOgK4VWaEMAo4hDlFPWBEwTIMJXA2K4BiPTA+zhiY3jlJwHj9YPImgg95nSJ3FqwI/l9BOmq6t1hZkDYqAxqy2dzBmDfkFZaR06fy2JYxBYf06tI8tRDAOsghKroTWeDTZIqhQR0DXitYReOM11TTUC1YEDNNgaDarZrVMpI5gsllDgUJx4lW2AdW6hjStpFb+qtaCqUWEem31czqHaWZcscOnHyPI+i4kyhpK21aiu0vdTjP+qEXgBtczpY9WbRHoriEtWEzX0Ntc15O6KQIhxE+EEDuEEKuUbbOEEHcIIVb7v2fW6/oM06qYYgTjcQ2Z2iNMBJpJ0wxVn9UD1buG9PTRtME15LoyEheIHB9UG4euIVKYpn78kaKtBPdLvuQGs3m6N88iMN+VqnAocCyUcZCgd2W8sjhtC2P9RaWCMsDLEhIi+r5kcD/Vk3pe6WcA3qxtWw7gLinloQDu8t8zTFtBX/Cx0gRdQ4bOmROBJupUzOUYXENVGgTx9FFFiBUMC9HEj/fy9NV0TlOMgFAFbLleQ6R0g77/lkj0vVsG15A6joLjBOdO2XGLwNSsr1LWkHeteB1ByXWRngoxAinlfQD0VTYuAHCN//oaAG+v1/WZ1ual7UO447ntVe+/Z6SAax95pY4jqp7BsSL+7bYXcMNjGyPbf/fUFryyayTxuDU7hnDbqq2BIM8rglF181z36AZIKfHzh9ZjcKyon0YpKKs81tXbh3Dbqm3Gz0gBlMsaMomim1duxsbdOTyydhe++rvn8NL2oVh8Ia24hu57aScef2VPolsI8ALV12vP0xQjICr186FgMWUXFR03yM7R3TqEOsunfaQyjk17RnHDio1BEZhKkj9/80AONz6+Ca4r8ZMH1mG04FRWBCLsQdQoGlO2FjJPSrnVf70NwLykHYUQlwG4DAAWL17cgKExjeScK+4DAKy//C1V7f+pG1binhd34sQDZmLp/GmVD6gjD728C1f+6WUAwLtevSjY/ve/fBKdaRvP/4tuCHu84dvePV9+0dEAki2C5b9+BrO6M/jCzc/i0fV78F+XHh85TziTr6wJ3ljmOesL3BgVgSbwXFfiE9etxNzeLI7cbxrueXEnJCQuPH5hZL+MMmN+busgvnPXanztgqOMY8ymLJRciX//44ux7YA5RqCGJJJSNAuKIig5YRaOqacQEFU4tK+UoUXwietWGvcFkOjP/8YfXgjG+NXfP4eNe3KY0xttdW2JeLC45MrWDBYLIU4VQvyV/3qOEGJSlQ7SmwIl/idLKa+SUi6TUi6bM2fOZC7FTAF2j3htBya6aEotMTVloxl9OfcH4RgsAt3Ns3fUswT2jMTbLdRqqUqSn5Q2SkHdT5x9aLCPLt7I/dE/nA9ejxXdWEGZvgbvSL4UW4WM6Eh7Td0GRov42JmHBNvDGEFcTKkWVFLWUL7khK4hxw2K3BItAkP6qDeO+PUzmpCuVG+xda/XdqJ/uBBTXLE6AgiUHLf10keFEF8C8M8APutvSgP43wlcb7sQYoF/zgUAdkzgHEw7IkJTvdmY0izH4+MnP3hkHVztBDQ71xu2AcpMfhwXNTVy04POdM2sUrWryzcac8q2UCx5+xdKbtkWE4CXDZTkGupIW+gfzsNxJfp6MsF2GofRIlCuZ3oOroymjwKhoE8SsNH0UVURxBu/6bP1Sm4cUuzFkhtYdDQOkxIpOfE4RD2p1iK4EMDbAIwAgJRyC4DeskeY+S2AD/ivPwDg5gmcg2lD6Csx2ZTJWmBSBOPJwaeiqLFIjCC6Dwlu0+0GbajH8ShyBkslVlnsSFhCWy1LswkoVz5ticAiyJecmKLRZ8y5QimSEaTSkbaxbdCbMfcpbpNMmRm8W8EiKDnRGAEQum+ShHY0fbSSRRA9R6XJ+8CoZ9kVHTeIzdgJikBCeq6hVrMIABRUV44QorvSAUKIXwJ4CMDhQohNQogPArgcwBuFEKsBvMF/zzAVoe/KJDMma4LqBiHFNJ5UziE/AByxCDRhVq4//0SyhkYNs3FTjCBlW2Vnt+SaS9lW0JuoUHLDtXdp1j0eiyBlY5vvOlGXiixnEajZqiYdTEtVqtZNkuDVP4++lkZFkNZdQxWE9kDOtwhcCUd6Qp6uoT9v1/WyhhoZI6g2WHyDEOKHAGYIIf4GwF8D+FG5A6SUlyZ8dPY4xscwAMIvb6tZBJRKmLRMownql1MuRlDOwpjIUpUmIRzUESgxgpQlokJck2+FoFVD6BrKl9xAKaRsLwdeF5S5fMmojACgI2MHikR1DZFFYFJM6vNKytUvaBYBxS3GU0egBosj++quoQoxAlJ05BqylEwhXYm40rMIGpk+WpUikFL+hxDijQAGARwO4ItSyjvqOjKGUQjnZ80nogikRArmzp1JkCIYK1NZHMQIyuShjydGMJI3dMY0xAjUmSoQd3mQRZC2RfAcPNeQ3/rBsjAGN64Iik5isFidcasWAQnbSpXF5jbUfmWxcu5UJdeQet8VYgR6llClGAG5voqOGxSkke7QQwFFx4WU5iB5vaioCIQQNoA7pZRnAmDhzzQF+tK0gEEQcduQ/DelXiZB7Yrzke6j+jXKWQTmY8phymYK6wfc4HfKtiKzWz1GQBZByhZBNbHqGqJF2HVBKaU5AwoIZ/5pWxi7bVYsKEuIERQdqVkEFdJHRdwiAMwWgb6tUtYQZb0VXamsU2xWTPT/1VLBYimlA8AVQkxvwHiYNqNaVw8JJNUXny85OOizt+CmJzdN6NpfvHkVvnPn6nEfp1sE+jbirue3Y8nyW7BlYBRLlt8SbCeLYKTg4Ku/e847jybVkxTBe65+OFjYxXElXtk1giXLb8GzW/birP/4E757l3c/g2PFyDVNriESpk9sGMChn/8D/vfhDTGL4KG1u/C6y+8O3pPySltR1xCNl9wvJv92/7BZEZDAm9WdidUtAFW0mDBoROrsqmYNVXINqRNwGpP099etEj09ttrir2LJtwiU56wrEbUKulFUGyMYBvCMEOIO+JlDACCl/HhdRsW0DaZyfRP0XVEF5p6RIlwJXH7rC7jwePNiI+V4dN1uzJ3WMe7jVCGtt3JW+f49awAgVkE9pFQLP7JuV+Q8BLla9PTRB9fsCl5LKYOq4d88uRlr+0fw7TtewsfPPhQv7xiOHJczuIbUmXQwC9VjBAA2D4wGr8P00dA1pKaPkiWgZw0BXu1BJmXhu5cch1WbB/E9//mQwJvW4VkDd//j67FeqdCulD5qsghGDUta0n1VVVkcqxwWEatvvK4hwssaIovAfCxlZrVisPjX/g/D1BTysVeCvpdqczP6Yo8nUKtScNyIe6ZaShHXEFkE0UwiIUTMT05Q+ug7T9wf96/u94+Jj820XcWRMhDGunDTXRfGYLFBeXlZQ/Fxk/AKZ6uWkj7qBs8kleAaAjxF0J2x8eajFkSuQbNrWpLyoDk9OGhOT/C5aTyRGIHBeMoV4gvYlIs56MQqh/3YB6E/32p7MpVcGSx1ScfoSkdVyo2i2mDxNUKIDIDD/E0vSinjTVAYZpxUm3YZuIYiAtf7PdE++iVHGhuFVaKgZQ2pvwEE+eskLPTZ/lC+BEt4OfO7RvKQUsb2MVUv63n4rgyFhq4MdddFuTqCyHG2uSnbaNFBTzYVWARpJVMqmj5a3jVEi7Gr2UEUV+jMxIOyNCadSm2oTYvc030lCW31NHqWmj6GmGuoSk1QKLnBUpf0P60r8YJidTWKaiuLzwCwGsD3AVwJ4CUhxOl1HBfTJlSrCOh7p2bn0Jd0PIFalaLjTqhlRaUYAQkhEjx6oHY4X4IlBPp6sig6EntHi7HnYGppvEvzsbtuaBHoylA/XyXXEGHqje/dk3c8deBM2VY0a8gNFQRgns3uGs4Hwl7NDqI0ye6MeV5qGo/ehlqfwYeuoXiwOOl/TnXDBb2G/PemFclUxuUakhIpywpdQwkpuq1YUPYtAOdIKV8vpTwdwJsAXFG/YTHtQrVZlzR7iixvKM2z4WopOq5xValKlAxZQ6pwIaFJriE9f54WLKdZcf9wPpYBNGaYwe/0FzQPri3NisB1ZVwRaGNwXZmYmmoSQLSyGClO2wp95hHXUJmA7J5cEd0GRUDWQ6JFUCFryJXxMdP9mtJHEycOyuZKTeXS48waIkquhOtKWFbY0C+5rqH1ms6lpZRBa0Ap5Uvw+g0xzKSotjrWFCyml/qiKNVSrIVrKLBK4hYBCQtKF1WxfYsA8FwmevYUWQTq1v6hqCJw3FAxqgoKxMYpAAAgAElEQVRyT64Qeya6VZL03AuOG7hqVOieTJZKQSsoo/szQcJeFfqpChZBpTbUjqmAzb/fTMoK/ndIsOqrqRHqVt1dY4oZVBqjiXzR8Ze6FIGVm6REGukaqjZYvEIIcTXCRnPvAbCiPkNi2onxFGIB8ZkvMPHagom7huLBYtVKCBSBLxxMawrYlqoI8pjbG81eMlkEu7Q8fKlYBKqg7x8uxCwCvaAsyT1SKJm7Xo76i87rsYuebArD+VIs5TEpM6fLIOxTE4gRODFFEN1nLLAIbAh4Qp7GlmQRqMolvgJZeddQpRYTRK7owJH+Upf+o9yXLIK/A/AcgI/7P8/52xhmUlSrB2jW5GgugXI8snZX2erbouNOyCIoGdJHVeGyducw1u4cDoTH4GjcIrAEMNt3Db2yK4enNg5EPg8UlDL8mEWgKILB0VDZ3PTk5ljMQHdPJT27gr+Ai84IuYbIleYf3p31hPcDa7zsp1SZthBAmBmkomcN6ZgLypTXMh6czvmKK5MK1ygOXUPmv7n6SOiatC1mEaQmFiyWEnjilT1IlWkxQbRcsBie5fAdKeVFUsqLAHwXgPmvxjDjYLyuIXVd3XKB5vte2omLr3oYP7p/rfFzbzYtJx8sNqzu9akbnsJZ37o3EE5JFsHMLk8R/ODel/H1Pzwf+dwUu9iTi55HzRoaUD77wb0vY6emNPQYQTmLwCTU6Hia+dPfrTvrzfAfXustRkjHJglGVdgfOrcHmZQVKCU6l47pXDHXkNYwblSJEQSuIf/voS9sdP4xCwAAB/Z1R84BKFlDFVxD5QwCPdV0696xSPpo0rNqxWDxXQA6lfedAO6s/XCYdqPafjn0lXAis/Hk/akIal2/eelIEtwTixHErRJTv3+6N3W2TlhCBNWlphgCrVmgZrLoM1k1a4iUzXtP8Vbz26tdUz+2rGvIGCPw22KUwkwhAOjVhHeQG+8LsQXTO7D66+cGrSNU19CtnzgNz33lTcE9dKbHYRFovYbUuEbaFkqw2A4SDUiwHjK3B3/69BnB/peetBgvfe1cLJrVpVwzer3YGsWp6l1D0zpSwfVPO7QvuCeyCEzdTb1rtp5rqENKGZQq+q+7yuzPMFVRbeonZViUqnQNkaAztSwAwlm940qjEC9HKWIRIDYu/RomQU+CI2k2aLII9NbUrpRBLIEE/4F9XiHWsBYTKGjH0vPRK4BLrjQWcOnBYrKkkmfx3m/LL6wjN5hqEaRsCynbCs6Z5BoyxggiriEZmaGnLSsYrylYDETTSoWo3DtI99frMYNyrqFev2LalRIH+4VyaosJUy8j75qtZxGMCCFOoDdCiGUARsvszzBVUXUdgf+dqFYRkEmf9F1ShaopE6YcRteQIROF3FhG11CF1EHTmBzDrJ5892R1zOzyhA6lewZj0c5Hrh0SQp2GfHuVUV0RlCoogiBo7L2fEVgEcWFP7qakYHHFpSq1NiXq64hrKNJdVDm/QYiT4KerxNJHq8gaIkuAfrsyvEfPNUQWQfVps/Wi2qyhTwL4PyHEFv/9AgAX12dITDtRfU993yIwCGET9EnSRE0V5oWSi+6seT8TRteQIQBJ7SuM6aO0gEvCl92UNaQrG1fKIE2SHsUMXxHoLZ/jbiXvdyZlAXlgemc6yDwypTOOBK4hJzK+ngRFQEKO3DLkEuo0ZA2RIkhykZgENSkyryo7OmNXXSqZlBW6hhRhHukrZPgb6LonHiyu7Bqa3pXG4FgpsAgABHUUUspgkpJoEbSKa0gI8WohxHwp5WMAlgK4HkARwG0A1jVgfMwUp+oWExQsNrSYMEH++aQcbVURjNciMGYN+eOarzSxM1kCBAkaU84+EMYIItd1dUUQrRjuSFuBy0O1CDIpK+YaIsVArqFpnaGANrliRrVgcWgRlM8ZocdPM2GjRaAsdmOiXBtqeiTqjF0NHGdTYQVvZOGZyJoL8fPHC8rG7xqiuEhvR/hsSRHmS27wbBJjBC3kGvohAEpefg2Az8FrM7EHwFV1HBfTJlSrCExLQpY7lj5KUgTq7NrU16ccRccNetiEWUPeOeZNDxXBXkPaqJ4pUilGoCo7U8BXzQbqyqQCoaJaBGlLxFxDEYsAYedPwCx4YzECf3y6ayhcUtSP0fjbaSZsEvb0/Kv1lQsR/n3p+auz55hFEKSPhtsji9AY/gTB3yUpfbSKrCF6puqxpAjVauxki6B1FIEtpdztv74YwFVSyl9JKb8A4JD6Do1pB6pVBDQbVitmy7mVAkGU8F0qRCyC8bWZKDoy8OvqdQQLVIvAkC1Ew0lalISgx6Leock1pBaSdWXsYFyqgrCEiCsRLUagCiPTTHQkljVUXnnqFhnNhE0L5ASKIMki0P3zdphy6hrSO1UBmrGt4JmnEqwA09+AFAU98ViwuArXELnp1GcVKIKiE1ilyRZBi7iGANhCCFL5ZwO4W/ms2vgC0+Lc/cJ2fPuOl5py7Up1BDc9uQlX3fdy2OXT4J/XuWHFRlzz0HoA4Rd+ff8IPnndk4HQqeQayhVK+KufPooP//zxWFZR1CLwtgWuoYhFYK4fAELBUcn8f/yVPbjoygfxmyc3x1xD96/uD1a+AkgR+BaB4jKyLBG41H7+0Hpcdd/L+Mi1TwAIhVAlwXj3Czvwvh8/EtQn0KPX2zVQYDechXu/yfVUzvrKJqSP6s8oY3tZQZ+58amw66km/IHQGgjrCBJiBMZgsZ41VN5VZLLsqE5EDWx3Ka4hGnvifbdQi4lfArhXCNEPL0vofgAQQhwCYG+dx8Y0iL/+mdct5FNvPKzCnrWnUh3BP1z/FADgdYfMBqBnDZmP+cyNTwev6fu7/NdP4+G1u/GuVy/Caw/ui8yuTYrglV053PPiTgDAjqE89psRltF4isD78uoFZW89dgEeenkXXtw+FEvhPO/o+ZASuHXVttA1VMWX/YkNA5jRtaViu+3OTCqY2dMM/q3H7gdLACvW7wEAfOHmZyPH0P5CAJ8/71U4auF0oyJYNLMrWDtB5Zwj5yNXdHDc/jOQd1y84VVz8YM/vYx3n7wYm/bk8O6TDwAAfOSMQzA4WsTFr14UO8cVFx+Hnzy4DkcvNC+CqAtZCnDfsGIT3nuKd/5osNicn6/uo062TYrAtDBN9FzR96ZndtnpB8GVEm87diHufH4HgKhrqMP/H8z6SuXf33EMfvzAOrywbch4jXpS1iKQUn4dwD8C+BmAU2Wo2iwAf1/foTHtQLWuId0Xrx+btOQlzUxpBkcz44KWNVRuXPo6AJ5ryIpcl6yGpfOn4WsXHmUcyzcvPCZQIKFFUJ353z+cNz6rMw6fgyP38yplu1XXkB8s/uZFR6MrYye2VaDnYgmBvzn9ILzm4NkxofbWY/fDZ89dajy+O2vjGxcejXe9ehHed8oBWDC9E1+54CikbQuff8sRQbXu9M40vnnRMcYso0WzuvCltx6Z6CYr1wmUgurqNnqm9CyCmglFMUSzhqq5plKnYItYfYrJNdTb4d3znN5w7YVQESiuId+6fOeyRTjv6AXhfbTSCmVSyocN25rjR2CmHONWBAmuoYLjGvOxg2AiNRyjts2l8jECVa/o7RmKyrUcLUaQskXZwqhgAfWg86Rx1xj9Q/nI+rtExrYCIdWVsWMWQcoSSFlWrBiNCF1DyjgtfSYtEoV0kl+/lsSqepVrBss6WlFBDYT3Rn8bVVmo92Ny6+j3q743BbxN5wjSQ+3w70auoaITVoWrz1C9TstYBAxTb6rtNUQCPdr5M/ycZvV6c7WilppI71UXk7F4S6oWQfycsawhpR+/qcMm4C+CrrVprt4iiLeWBjz/Mgm4TiVriCyClOVV9upZQ8HxVcQIvHE3L9ddLyhTBScV1KWMFkH0b6Q+a3VGb6o+13sNRdJTDfds+jNS/UJWWSVNnSTQ/4z6uYgoZFYETIOodkbe7OuT/Fera1VhTcK8X1u8hRQHdYssVOkacmV51xC5eMLF6728cNtKtgjSthUIo0qLkugUHDfSWI7IpkKLoNtgEdiWQDolEnsqqTECIqYIhHn5Su+e6i+sjDECH4rDpCPpoyKyX2ARJBWsGe6NrikN+5ju2RRnEP7lVMWl/m8Ug1qOcJt6npYpKGOmPntyhco71ZFqK4uDReITWkwkK4Ko+R1kDUVcQ8kN44CoRUCrf4WzTQTjImGZpAgsEQqUoLJ4HIJ0296x2LaMogg6M7bf3thvzWx5vuy0ZaHkSqPCo2PVWXEsEGqLxHE2wjVUzl9P2VGm1FA9WJxJuAeTjtN9/lHXk8E1ZEpBpXFELILQWiwaLIKoi44tAqZB6IKz0VS7zCTN6iLpo4qwLgSKIKrYQteQ96Ua9WfKJcOxKqqhoioCmsVltawhb4lH8tUnt11Ia66hapc4BMw5+J5F4J2jO5OCECKYCZNwStsWHFfGspiAUJDbZVxDFGcw0YhZq66EVItgyK/eThn87HqhVtI9VFNZnIpYBAbXUNkYQbh/hyL06X9HVVhRi4AVAdMg+odCwakK1sGx+ILqOiP50oTW/FVxpcSekcpWSbASWKSgLPycxqErtsB3738ZcwUHA7lCRPjnSw7Gig5G/c8ALWtIEaB7RjzBo2YNlRwXu0cKSiBYGAu1vM98n7y/uZpZn7q+r45uEXhji1bxUvGTqcCNZqMR15Am1NTYhk5DXENlsoY27h6NbaP99eSB8biGaAsZnSmD66nyOcjqM8cmiEySImihgjJmirNbcQ05SirkMV++HZ+/6Zmyx77vx4/g3257sew+lXh03R4s+/qd2Lg7V3Y/PTsHiApraou8W1Mq5Bsngbt5YBTHffUO/Psfw3EXSi6O+crteNUXb8NxX70Ddz63PZKOmlNm4h/6n8cAhH1kHCnxi0c34MbHN4XSA2EzNj1dMrAINBdRORYoRWq64M2m7EjWkLdNswh8gWIqcCNhowogy3cvhfuIWEuFcDwNsAjKuIauX7ERQPQ52+N2DcW3k7Cn+hV1DNRJVcWUNaRvUuskFs0K61JUhaXearXxo1rAiqDNUX3lembOr5/cXPbYbXvHsG0w7rceD1sGRuG4MnEBGcK0NrA0ZPbo/n49S2jHoGcx0MI1dIxqITz2yu5IIFrNRBoaK2F2dwbvOHF/AN4zW719OPiMoHbQuiKgL7epIyYA/PyDJ+GC4/aLbFOblukppNFgsbcfzTBJadDvAV8RqDUBJKx0oRVpymaJxMK3RvixdUGtC/jjFs3AOUfOD97T2Gd2ZyL7JbqGDJuzKRt3fur1+K9Lve779Hd654n743vvPiG2v+kc6rj/9Okz8Iu/ORkAcP9nzsTvP3Za8FnEImig8FdhRdDmmNYAJj94pX/JgiMT0xLLobqgyKWza6R8rKJkcA1FhLW/Rq1efUuKg+oH9PbM6hiIjG1F3E4jSifPkiNxxuFzgziAK6Vx7LP9vtZ6UzYS2vSs9dTIo/abHgvAqspEb0egxgg6NYuABB+5RMgiUGempJB0Yavns6cTBFQjZq3l6ggA4O3H7Rd5ZnQrukstyTWUFKc5ZG5P8EzpmrO6M5Eqc8IcLA5fL+nrDtpRL5rVheldoVWRFCNoJKwI2hyTq4WEZ6X/yZLrxvrfVIMx7XOofJzAXFAWfk4Wga6YyDVEVo7JPaIHi9O2FVFWpGS887jIpETgCnBc89inBxZBVHCTwAgUgfaMLRHP2VeViRpsBKIWAbmGMr7VkOQa6lLOR8JKl2Pq7Nm2LKOgo6ykelOpJfTsnmxkRk6ZRH09UYsgKZ5RzcLzQV1BwufG9NEqn40pRpDUiK5esCJocxxDywaaVYsKNkGx5Fbsf2O+pinbp7xFEFor5qwhKqDSFRONjxSCrgiyKSvmTlK7WwJa1pDjIm1bgeBxXWkcO8UQdIuAXCl0et0iEFbcl522w+Bzh2YRZCKKIBXcEx0HxIPFanprsMZwBYvAlB3UqKyWSstE9vVkI+Pf49dbzOnNlj2OqGYWTo8jqZVJuayhSkQtAu+3/neuN6wI2hxTf38SzpW+H0XHnJteCfW7REJ4ZwVFQNdxEtpQU9GXXjhFFgRZCroi6MmmDBaBiDwX1TVUdLw0UXVmb1IE1Ited/OQMAqyUUzFW4ZjqDFZ3CIIK4tDiyCePqree2dkvV4KEkTHry/iYooFJAWQa41uEeiZWHN6MxGhS5lfs7urVAQ1uA1j1lC1FoFhnQT971xvmtJKWgixHsAQAAdASUq5rBnjYDTXkJaZU+7fWEqJojtBiyDiGvJjBMPlXUMkrFXXUERYK66hjrQVNCPTg8W6IujM2AkWgfe6O2PHXEPplAhmgGNFB4OGpSipF/2Ydu7QxeC7hrRZNS32ro8nm7YwlI8KcUALFmejMQLaTjPqvf5MWbVS6Or6jNbSFYEpZbJBFkFMEWjXnd2djWS/UeZYX291rqFqLAKyjpPqH6txLyWe29ASu9EWQTPXFDhTShnva8s0lEiwmKpkfeFZ7gviuBJSxl0x471mUkWwTt7QI0j9UlJmT8mVmN6ZxljRO18YI3BjxwDeF063CFwpA2ujpyMVcw1lbCt4NjuGzOMm15C+9jAJIzfBIhAiwTVkV3YNdWquobCwyvu91+ga8tNY9bbLumvIMG1uVJ57bD0CzSKY3pkOMqIABIo5Fiwex1KYOtqCZTFq9ShoKLrCrze8uMwU588v90NK4HWH9Bk/VwVryXXx8s5h3PCYl5utmgTbB8dw+7Pb8L7XLAGgtHNWhOi1j7yCMw+fa8yqUDFXBOcxVnTw0wfX47B5Pbj7hR0RgUX7rdkxjMdf2YMTD5hpbAxXcFw/jdIT0CXDOFUythXLGio6bqAIurMp5PIO9uaKuO6xDcFC6SQ8tg+WVwR5TRFQTCAMFsctApNriDJe9CKpbMoOZutd6WhBGZ2HBOBtz27zP49n2JRbrN32u48KEVWkjWqBoE9IdIGu1z0QtDBM0nHEeCbziRZBjZ5F2JaiPWIEEsDtQojHhRCXmXYQQlwmhFghhFixc+fOBg9v6vDuHz2C91z9SOLnukVw7n/ej6sfWAcg6hr67cot+MLNzwZVwJRiSjPtkXwJn79pFX731JaKYzJlDe0aLuDKe9bgX297AR+8ZgWufWQDfnT/ushxNCv+yYPedlOMoFhykUlZOHbRjMj4TJbLG141F9l0PFhcdGTwXHqyKYwWHdz5/HZ889YXAHjBVzuwCLw6iqMXTsd7Tl4cnOP1h83B/Gkd+MiZ0RVddYvA1OnT5BqyE3zHmZSFExbPxOmHzcE0X/mQAqWUT3Xmfvi83ogr4pwj5mFGVxofeO2SyHnPWjo3eJ0KzqNZDQ1yDaVtgYP8dQ289+H9vMXv368qi29ceDROWDyjbEWyymTcOqZzXH7R0XjVgmkVj1l+7tKgYI0gl1yjs4aaZRGcKqXcLISYC+AOIcQLUsr71B2klFcBuAoAli1b1twWmVMYR4sRqMFWVWBQ/v1IoYSZ3Zkg+FrSMo2qiRlE6giKoUvn2S2DwfZpHamY7/2vXrcET24YQL/vjnEVYZ1TXEMpW+Dmj74On7vpGdzuz4L1cd3y8VNx5H7TcclVDxmL0EjHeK6jPMYUqyGjZA1RgdqV7zkBi2Z1BfvM7M7g4c+djV2ayysQTrTWbixGEBdYaTtUPLprKOsrvdccHAqUPj9bxtJcQwCCoiZiwfROrPziOdD56gVHIV90cf2KjZFFdIqOg4xtoeC4DbMIhBC4+9Nn4Piv3o49uWLgGjpiwTR8/z0n+PuE+7/75MV4t6KUiclkDdF3QSY4h9TvyiUnLcYlJ8Wvr/Ph1x+MD7/+YG0s3u9Gu4aaYhFIKTf7v3cAuAnASc0YB6NnDUUFovr9IEEb5Otr2ThhwVdlnR3tERRec/WO4eC1yTS2LIG+3kwQT6DzqIqA0jsBT2CbXFhAKBQyqXiwuOi4wXPpTNvIl5yghQUQXahlu28RJPUD0u8jFbiGvPf6rFUkBIuTLIKsIbtktl9RS1aSej7dXVLOpREEtLX1h0kQN7JNMhA+s6BRnqHjaDmSs4aqCRaXp9aFdY3OGmq4IhBCdAsheuk1gHMArGr0OBiPaEFZ9DP1X5uEiipwgbC/f0n7XQ7VNaRef4PSb8hkGttCoK8ni10j0cZwXkDXTx8tuUq2jEh0DdE+2ZQVUxIlRwZj7PSDyaqllE6FweKBXBHdGTuoQNXR00eDOgJNyJrGpr4Pskm0GIGpDTTlz9P6BdG1epPrBXToz0TXTlmaImhwOwRyBZLFZI1bEUwms8f7XY+sIRX6f22HrKF5AG7yTakUgF9IKW9rwjgYmAvKCNXcDSyCfLSVQ0mLFZhW0dKptGA9YP4iWJbA7O4sBnLFSEBXdw3RbCqdshJdVmlldqsHiwuOGxQOUXqpahGoghnwKluT0IUPzappOHpBmemYtC0Ui0BzDRmeE1knpAhU15BOOQEW/JkEjT20tLz3jVUE5JWhwLl6+Wp00mQa5NHpEwvKajSlprRn07Kk9aThikBKuRbAsY2+bjuS9E+rospHfZGYiEWQL+8aCvryV2MRVKEITBZByhKY7bcN2DVcCMbb25EKfPVFxw2atKV915CU8Z5IqkWgCnk6Bz2XzoyNkisjawGoghmItzJQ0YuKaHYuE2IE6tjU90lBRJNFQIrAtHqXTjkBRlYLjZAsAHJHmZRYPaH/mrTJNVSFJqhnp9RauYYo3XjKu4aYxpG0PKGKahHo7pNIjMD/B6Xf4Uw72gyumhiBvk7x9M50bEZnsghsSwRCrn84H4kRjBhcQ5Q1U3JlpDUFoCoCO7bgS7EU1hFQ0I4WQKFj1fGWWy9AhwR/2GKiOkVA+kLPoTfGCDTFVM6XX00tgNBjBNrzbRT0N5lojGAywjoMFpupVbO4wCJoh2Ax0xj0hdxNJPX3BzTXkD+71F1D5EYxdQdNQncNpW0Ls7R2ACaLwBJRRRBJ8VRcQ4Gg8s9RdFw/iBzeD73OpqygSRlRdF2DIigpx1oQIsxdL+ca0qFZNZ3f2LrB4E7S20UQpucUy5/3jzVlopTVA5rUI6VByqjRLZPDRWK860YVQUOHEqN2isD7P26XOgKmDJ+58SlcccdLxs/e/v0HsWT5LXjtN++KVa3qjGhr7ZowtaEmdg7lsWT5LXBdGckaWrF+Ny688s+Rc5iCxXc+tx3n/9f9cFyJ3zy5GUuW34ILvv8g3nhFJFMYaVvEGoQZg8VW6IbpHy4E7pVuxSIoOm4gKOgcH7n2CRRLbqS1QsQ1ZKgjoOdFQeCoRRD90s8p4xrSodk5PSWTAIkVTImwpUV3tnKwWJ/5ksA+cr8wt/2gOV5efrkYgRYiiAWLaxUgrZbFfnquaTGdendBpZYhev8iolauIXJrzp/WUWHP2sKVxS3IkxsG0D/L3HvnuS2DyKYsbNk7hsGxYlkTclTpvV9wXHRY8X3LWQTBeYpO4D7JFUqRfH/AE5ym9NFntwxi1eZB5AolXO4XYz21cSB2/pQt8MXzj8Cvn9iE/3t8E4B4BS3g+aRJmI8WSoEfv7cjhbGiC9f1YgEkSM8/Zj985XfPYV3/CIquxMxsKgighumjoSA99ZA+PL1pAMWSC9JnHQkWARAGU6nPfBK//JtTAkVXnUUQFe5U2QsA0zsz+MF7T8SiWZ3YOjCWKAB/8aGTMc9f2ayvJ4vvvft4vO7gsLr8ustOwcoNA2XdRqRo6RJBywqbLIIyN10Hfv6hk/DkhoHYKm9A/S2Ctx27HwolFxcct9D4ea2u/5evXYJpHelg4aNGwYqgBSFXho70C74WTO/A1r1jgX8+CbVHTr7kGpWGW4UiyBWcwH2SKzixIGHBcYOFX0rKuAuO3/ah5BrXASBSloXXHDwbB8zuChSBKVhmi1Bw50tuEGughVtGiw6KrgwE6ZzeLN554v54YE0/io4bXc7QEHx905HzsCdXQMlVsobKKAIiKXWUUIu9YjECY7A4XmRG401ZAm84Yh4A4Mj9pseOJV6rtRQ5/5joqmdzezsiq3qZCCwCQePSXEMNtgjm9nbgTUfOxx3PbQcQtUjqPRYhBN65bFHZz2tByrbwrlcnX6desCJoQYqONCoCcmHQrLhUIRistk/2UiTjM9eqLIKCE/jgcwUnNostOa7RIqBsnHzJjQVkVUwtDMwWgQgEd77kCWshwpYKI4VSLBaQTVsYLTqQMr42gH6dlG0hZVsoKC0mOjPe9QbLuIZ0d005UlqvIZNFoM/SheIaauQ6tqSs9GU16W/QiEVpTNDfZrx1BEwyrAhaEM8iiAtlygIigVapnYPaPjmp6ZreYsIS0cpfwBOwOcU1pAujomOOEdB4K61ZYFrIXc+OAbwvPrklCiWv+tcWIliQZbTgRFxDAJCx7cCaMSkC9Tq2JZCxBYolN3gGVVkE6eq/RvrCNCYBpvv9bRG6hqpJva0VukWgxwiaFaA1NexjPTA5WBG0IEmuIZph9/oCrVAqLxSiFoFZGKtZPq4rYQkRCxrvyRUCAWRyDRUd15g+qloE5dD75gPmmS8tjZhRAryWJQKLIFeIuoYAzyIgpaovGwlEXUNpW/i1B2HWELnThvPJiqCrgmtIhQR/2RiBVgBmWeFxeuptPdHrUIKsIbs5riGC/hfHmz7KJMNZQy1IyZFGi4AqYMkVUSlVU00fTbYIlOv6ikBHXTQmV3AiQWiAYgTx9FEar165qxNYBIrLxSQggxa9ttcWwvUtmM5AERhcQ4qg76loEYSuIYqdkLWhMhnXkN6qwDYtAakvXykEaLdqqrJrRWgRaHUELWIRRF1DzRnLVIEtghakkGARFErjcw3lFIGdNCt3XDfoJum60mhiq4vGmFxDJSVrKLIesT++4Xx8BS+VIAtEubgpiBoEeNNeWwhL2LCFCJ7H0FgJUkZn7KqgrxQjSCuuIUcLFkfHO3HXUKgIki2CstXZV/MAAB7+SURBVK6hBloERFL6aLNjBCm2CGoGWwQtRMlxcf/qncmuIV+Y9yiuoXzJwYNrvIXeHlm7KxD+JcfF9Ss2hccmBGtLrgy+2F6MIP6FUhXBw2t3Y13/SOTzrXtHsdJPCy06Ltb1j2B9/0jgGrr5yfJrFJhiBCYBGWb62EHWkCVEIKwpMyniGlIEvckiyGoxgrRtoeSGMQJT9pKuCMZjEYSuoeg9Rc6vuYZsKwwWNzJGoBeU2YFryLvfZs3CadJhcYygZrAiaCFue3Yb3vfjR+FKcxfPgqYISq6L3z+1Fe+5+hE8/spuXHzVw1j+q2cAAI+u243nt4b5/kntJhxVESRYBNTHZ9Esb+WxNUq7aAD4y58+hh/c+7I3JkfiC79ZhS/cvCq45vUrNpa9b7VbKGEqVlIrWwslb80AywotglARmIPORkWQVmMEnmuICsosYQ5a6/2BKqWPqlBh0ntP8frVl7tP4uA5PXjrsV7651ELk1NGa81bjlkQuWY65hpqjvQ93l906NyjwvTXctbJwhmdWDA9XqB10oGzaj+4fRR2DbUQ2/aOBa9NgltPHy06LrbuHQUAbPWPfWn7EIAw3fGrFxyJL978bKyxGqG2ZEiabVJ76O9degL+9uePY9vgmHE/Ot/gWBGWEBEXxwmLZ+CJDfFiMiCcFVvKcoimhmYUlM36HUMdX1jT9r05k0UQvtZbL6jnpHGkbRHEH7x01biQ1103pjhCEl2ZFNZ987yY3910/nOOmIcfvu9ECCEwf/r8yHGN4LyjF2D95W8J3ttWayiCQ+f1jutZPLj8LGMDxhv+9jW1Hto+C1sELcROxQVjdg157h3VNdTvB3KpWRV9OSljiErVkywCV7MITE3jNvqKYE5vFofO6yl7DyXX9fr3l9xIkHixsnoXQUI4ki1URkDSzJssAhLWtN3sGgpf02w8ck7Fv5/yF4kvuZ7biTKUdOIxgvH1hVEFWDnXkO1nSZmOawZqWw6gue6Y8T6LZj+7VocVQQvRPxRm51TrGiL/PfUdIsFCef8z/dWqkjJ31BiBK82FbFt8a2N2T6Zip82SI73+/SUnEqCmxdxV6D4iLiFDvIDo9mfe1B/I9YV1lxYjSCVkDdGziJxT8e+nLAspW/itqz2lZGyHrSmpyRR5GQvKqJdOi6XCxFpMsHCdMrAiaCHUoGy1riE6Rs2rB8I+QzP9WXC5gjK1SCspKaW3I4Vsyi7bex/wFAut6FWopAj8BlspQ9qoSUDGLALXE9Yp20ImZQWKIJOQNUQNvUznpHGkbcvLGvLdTiZFkK5hk51yC9O0mqDVYwSNrHJm6gvHCFqIXSPlXUO6RVBUXEMk+Emmkmtomi+AkwvKZCDsxhLiCAAwx7cEKrVcdlzpp3YKuIrHZJpBEVBhnOpqCeIFBiEYxghsDI6Wgkpo+qxS1lCXIc1T9e+nLctb59hvQ21ZwtiUrZYzdVPPN2/dYgGDd6yp6JZKi+kpZhKwImghVNeQlJ5QVWddekFZ0XWxy7cIhvNR19Bo0UFn2g4qY5OCxWqMoFxba3IJmXLxVYqOt6yjbYtIqwqTRUBCOpI2WmYZRHINZWwvWEzCmj6r5BrqMqR5qv592xKBa8hNKK6rNUmrfKUsq2VdQzSsVrNYmInDiqBFkFJGLALAE6q20jparyMYLTjY42fKUD+dMFhcQlfGDgRhUrC45LqRRm5J9PV6LqHuCqmSjiuRd1zYroBjh5rApAjCrpbxwiCT24HcONk0uYZCYd2ZsTFYwTVkagWhXodaTFDQvBGuj6QF4D2LoLUEre6yajE9xUyCto4RDOdL+NufrwhSMMdLrlDC3/3v49i0J5e4z5V/WoOfP7S+4rn2jhZjbSVIeO8eKeBD1zwWpIjSrHy7ksZJ1buBRVBw0JmxA6GoF5T9/ukt+M87X4KjuIa+d8+axPHRghymXHyVohNmDCXFCKhIi4S0GpdQYwS6HKT9w2BxeL+qayhqEYTCv9KC4FRQBnhKsRGCLknZZFJWy/ngbSu6RCdbBFOHtrYIXtw2hD8+ux1vPXY/nH9M57iPX7NjGLeu2oY3HTkf+8+Mp0cCwL/d9iIA4H2vWVL2XP3D8YVoKHPoZ39ejzuf34E/vbgTQBhk3bI3WRHkCg66MykIIdDbkYqtB3DL01uxcuOA13FTC4ieftgcSClx/+p+TOtI4eSDZuPtx3sFTWcunYsPnnogjtl/OgZHi3h+2xD+8MzWYMEX6m/kyqiFMV1J3fzOJcdjxfrdmNvbgftX90cURpg1ZEHAvEYsBYsdGRbAdWXsYEU2dd0F9d4sS+Dyi45O/FulbSsIKA/kCoGg+9x5S7Fy4wDe8Kp5kS6k37nkuEmvLXvs/jPwl69dguMXz4hs//jZh2Lp/GkJRzWH849ZgOmd6aDXD+uBKN9+17HGWpV9gbZWBGqP/YmQm+TxKmrGEEEBY1onOGULlFwZ+MrVArQRTRGMFEqBK2VOTxb9I1FFkys4yBUcdGXsWF78RccvxN7RIu5f3Y8LjluIf3n7UcFnadvCF84/IrL/m4+cj/f/5FH/uuZnMU1ZxWvhjE686S1H4LpHNwAA8orbKlyPFsZOqEDYYkJKGbhP1KCv6gLSs34uOWmxcXzeNcM1kXcM5QNFcNnpBxv3T1qtajx0Zmx8+W1Hxra/v8LEoRkctXA6jlo4HT9/+BUAnJuvc9EJjV1VrJa0tWuI+vJUs8i7iVCRlG+qVg0mRUAzZaoJsPwCJ6/3TIIiEKFriATi7J4M+oei56fFZtT0UYL85EB1KYKmFEud7kwqcPuQ4iFFlWgRJFw6sAiUGIEq/FWlYCoISyJlC8z2aw12DOZbzjXTKlCVLj+eqUObKwJPwI5MUJDTcbWwCHaZXEO+MCaFky+Fgd20bUVaPZBryFJcQyQQ+3qyMUUzUiih4LgYKzoxYZm2w5l4NX7gaoRtp2J5UNCRxqemygaVxZYIVsbSyaa8bqmOG2YNRRVBskVQjpRloa+XLIKxhq/Ju69ArbA5RjB1aOt/dRLgE7UIKrmGTP1NkugfzsdmWCQgabavBnYzyqzd24esBhpbKRCIniKIKhq656F8KeYailoElcdu6sejk0lZgQIILIJ0OYtAIEEPKOmurlJHkOQaGscyknboGnIlC7ok6N+On8/Uoc0VweRm9KOBIjFbFJVW5lLpH85jVne0WIsEpNrPnwQb+dKn+cHNYS19NKe4hvp6stg7WowIXLpnaRB4adsK+t5Xk8ueNbRqNhFaBNGsIXVcdF8p3/1lvJ7/DEaLTiRriIgUiY2jKitlCUzrSAWuslZL32wVOFg89WhzRTA5Hz+5hpICpONRMDuHCrH2DeQaUt1GqmsIABZM97KdSBHQMapraLZ/3t1KwFh1h5mKt8j8r0YY6jGGJHTXUMZQ42Ar1avlXEOAp4iFFiPIammX4wlopiwLQojg78CCzky59ZaZfZMprwgGx4oR18+u4XyYjeNv3zVcwOBYEev7R/DKrnDRlXzJwZ6RuO9+h++bH1VcS3tzRYwVHYwVvdcbd+ewavPe8JiheOvmHUNjWLlxACs3DmDTnlysodvmPaPYO1rEi35raSAUniRU52t91kcLDgZyhZhrCABe2TWCpzYOIF9yIs9ED4oOjhUDhVJVsLhai8DvqplW3FuA5hryL2eqIyDUSmjav9NXeuNZP1iHgtnURoODxWZcDhZPOaZ8+ugxX74dC2d04sHlZ8FxJU782p248PiFuOLi4wKXzu3PbccxX749OObRz5+Nub0duPKel3Hj45vw4PKzgs9e2j6Ec664Dzd95LWBXz5XKOGSHz2M0w7tQ8oSuHnlFmweiBapnfT1u/DHT56Ow+f3Btve8d8PBb3+AeDiZdFc8o/+4olY++bQIvC+hfOndQQ9/AHggTX9OO6rdwAIs3Lm+FXBf3ftE15x2qkHRtpN69Wtc3qzwZf8iAWVc9mr9cNTszb6TdXK6gIh1M/GtqL2wGFK+2t1QflZ3dGK56S1AQ7s604c12mH9uH+1f2BG4wsKJ7xmqFW5Efu17hFcqplmqGxIFOZtnhqJJRH/TTMm57cjCsuPi7RpbNlYAxzezuwtn8EmwdGkS85gbCjZRrX9Y9gtBi6hrYMjGLzwCjSlogpAWLnUD6iCHYMjeHco+bjXcsWAQCOXzwjtprXht05zJ/WgY60hfW7coHgI4ugrzeDtGUZW0h0axYBuYZUCwOICrxbP3EaXuUL/zv+4XQcOq8XlSiXmXPth04OBIfuGprb24F7Pn0GFs4Ii/loFp6yrGBc137oZBy7KFSSs/yinf7hPJb4Ar4zUARxpfTn5WcZO48SV71vWSSrioLYrAjMnLV0XtX/G43kkc+dPekCv3ZlSisCfcUtPRaQlC1EOff0e9dwAfv5wooERv9wPpJ1RD/FMvaymibpuBJjRReHz+/FmUvnlr2PNx81H89s3ov1u0L3EQnV2d1Zb1Utw62o6aMqqhUCRC2CVykWQLVf9HIxgkPn9mBur+e+Sqc8d4/qctFn6mFBWZg1tP/MzkhrC7IkvMweb1tXGdfQfjPKV413ZmwsUiwvUmycPppMqykBAJg3Lb4cJVMdU/pffbdeTZuPSsukILEq7NXfQNghtH+4ELiGBseKKDguRvKlsgFiddZO1kk1Pu05vdlgljo7UASeBOzrzQY+dx11lqwuwv7KrqgisCfZ77hcZpG6GEzKspD2A7JJqOmjQttGzFayq+izSq6h8RD022eLgGkTprQi0Lt56kI6yTVUVhEMh9YCuYYoq2e06JTNQFJXHaP9qhFcfT2ZwJqgjJbANdSTiS12TlC7ai8TJnkdgaQOmLVArVHI2FbFdE61oMxSlILKrO5MrBVyOdfQeCE3ILdQYNqFpigCIcSbhRAvCiHWCCGW1+s6an9/AIHgDt4nKoICSo4btHhWzxMogpFCoFgodZP69yShuobo2tUIrtnd2cCCmNMbdQ319WSRSRCu6nq8pAhMawcn9cSvNemUSLRewrEYLAJNINuWCGIlpAioI2tnTRQBr8DFtBcNVwRCCBvA9wGcC+AIAJcKIY4of9TEiLVVUFxDY0XH2FqiO2OjfzgfcSv1K5YFzf77h/JxV9M4XEM0lmoUQV9vNjgvCXTypff1JLuG1HPTcUvnx327jVoJK2VZidZLsI9SUEYzcpPrqU9L8STXWXcNXUOsB5h2oRkWwUkA1kgp10opCwCuA3BBPS6kKgIpZURI7x4pGC2CRbO60D+cx05DXEA9Z/9wHjnNwsgVy1sEqmuIrJNqXUPUgZRSGzO2Vzg1ozOd6NpRF2Ynl5JREVRZEDZZ0raVaL0EYzGkj5o6dYQpnt57Unq1sQh811BSjwuGmWI0I2toIQA1R3ITgJPrcSG1v84//+ppPLtlMHj/9T88bxTai2d14ZF1u4N1BABg454c/vPOl3Do3F6s9dNHd40UYqtu5fIOUnZyW4mi4+Lq+9fixW1DwXmqsgh6skEHUgqUpm3L85Uri6nodGbirqHDDT3u6xkjUMlU4xryh2IrFoE0rEpA96O7hroNy1GOf5zeGItu9S1CGGZfpmXTR4UQlwG4DAAWL07uIV8OVcDdsGJT5LNbnt4KAFh2wEyseGUPAM83fNbSuVi1eS9Wbx/C0vm9KDou7nhuO+54bntw7EkHzsKj63Zjt68MaNGXguNG0ji/ceHR+NxNzwTvi46Lb976AqSUQeMufQb7jQuPxq2rtmJwrISjF07DnlwRHWkbV7zrOPzX3asD3/hph/Vh/5leWmRS988uJaf61EP78NzWQbz24NlYOr8X2bSNA2Z1YeXGARyxYBreeeL+iQu2VMPFyxah6LhYuXEAi2Z1IV9y8N5TDojsc9qhcyI1AyZUi+Df33EM/vW2F4K6AZXXHzYHj67bjZMPmg3A+9u9+cj5OPnA2RO+B4JiBCWn+qaBDLMv0wxFsBnAIuX9/v62CFLKqwBcBQDLli2b0Dfy0286HItnd+EzNz4d2f7VC47EF29+FoC36tJnz1uKv/jvh9CdTeGSkxZHFi+57H9W4OWdYduJi45fiBOXzMSj63YD8CyIZ5RWEoQlgEtPWoShsSK+eesLALygsuNKHL1wenCM7tN+98mL8e6T44rvzKVzI/UG7zk5FLJJM3p1sfZTDpqNU3yhedsnT4/tqxZsTYR/fccxFfe5tMyiMES4VKUVu2eVi07YP7IQiBACP3jfiVWOtjyBRZCwzjPDTDWaESN4DMChQogDhRAZAJcA+G29LmZyvSxSZr59vdkgu6bTUJU4W0u77OvNRs5pysLxrustE5lS3DZkOajH1CLdcbQYF1i2JapuBtdK2LY5ZbSRBBaByxYB0x40XFJIKUsAPgbgjwCeB3CDlPLZel3PJGjnTguF++zuULCb9p2jdQSd3Z2JBHgXJSgCcvmos3VSBOoxtQhuDvrnnaGsC9yVtvfJPHh18fpmkQlcQ2wRMO1BU2IEUso/APhDI65lysqZo8zy5/RmAhdKVza+L61YFbzvqc4ioEpXtcXzoNEimPyfgM47f1pHsIh8Vw2Cps3AKpMy2igoa6jIMQKmTdj3fAfjxDTLV9seeILd71Njcg11m1xDofBWZ+EqlLGTtuKuoXnT4i0SJsOQn1qqtqSuhYJpBq1gEVBbbY4RMO3CviktxgEJREuES+ylbQszu9IYGithWkc6SE40pR7qi8X09WQiXSmTfPxkEdgG11C9hPRcxXqpReyhGbREjMDmGAHTXrSBIggrToeUJR/7erLIpKzABdGRtiJ598F+mmtoTk/Y7sE7v/kRdhpcQ6EiqI+QnqGkWe6rioAtAoZpPFPeNUT9yY/YL1pINW9aR9AeGQB6O9LGnvXU24eWQJypBYtNArcjbWFah+cyShlcQ7UoelKh2bMqOns7zC6rViebspGyRFMtgozt/X30NuYMM1WZ8hbBrO4MrnrfiTjpwFnYtGc0EDD/7/xXRZZI/K9LjzcWO03rSOPq9y/Dolld2Lp3FGnb0hZKt3H3P74eu0cKWLNjGK4Eli7oDRWBYhGM+WmenZkU7vzU6Rgam9hayTr3/OMZ2Lp3NCh6e+ux++FjZx5Sk3M3mktPWoxj9p/e1Iwnsgi4oIxpF6a8IgCAc46cDyDqOlmqtVqgYisTbzhiHgAEq4up9QZdmRTmT+/AQXOAZUtmxY41uTi60nbFCtvxsHh2FxbP7sKtq7YBAI5bNCOyEtq+xJzeLM44vPxCPfUmWEuZXUNMmzDlXUP1wLJEoAwqpWmmDEVd9UrtpEXFG9VNdKqSTfPXgmkv+D9+ggRFaBXWSNUtgnpW/JJPm/voTw6qI2CYdoEVwQTpzNjI2JZxxq+iK4J6VvySRdDMYqypQFITP4aZqvB//ATpzqSqcvGkND9NPSt+A4tgH2wt0UpkWREwbQb/x0+Qzoxd0S0EILYiVz0rfim2yRbB5GhmDQPDNANWBBOkK2NX1TBO99ebOpzWijBYzIJsMuyLzfoYZjKwIpggh83rrSpFU189rMfQ2K5WvPXYBQCAEw6YWbdrtBOXnrSo8k4MMwVoizqCevDltx1Z1X56jKCvN77aVq04a+k8rL/8LXU7fzvBz5FpJ9giqDO6v7lPW+iGYRim2bAiqDN6eqne1pphGKbZsCKoMzGLoI6uIYZhmInAiqDOsGuIYZhWhxVBndHrCFgRMAzTarAiqDOxrKEedg0xDNNasCKoM5ZWnDSbLQKGYVoMriOoM50ZG8vPXYols7uxftdIXQvKGIZhJgJLpQbw4dcf3OwhMAzDJMKuIYZhmDaHFQHDMEybw4qAYRimzWFFwDAM0+awImAYhmlzWBEwDMO0OawIGIZh2hxWBAzDMG2OkP46t62MEGIngFcmeHgfgP4aDqdW8LjGT6uOjcc1Pnhc42My4zpASjmn0k77hCKYDEKIFVLKZc0ehw6Pa/y06th4XOODxzU+GjEudg0xDMO0OawIGIZh2px2UARXNXsACfC4xk+rjo3HNT54XOOj7uOa8jEChmEYpjztYBEwDMMwZZjSikAI8WYhxItCiDVCiOVNHst6IcQzQoiVQogV/rZZQog7hBCr/d8zGzCOnwghdgghVinbjOMQHt/1n9/TQogTGjyuLwshNvvPbKUQ4jzls8/643pRCPGmOo5rkRDiHiHEc0KIZ4UQn/C3N/WZlRlXU5+ZEKJDCPGoEOIpf1xf8bcfKIR4xL/+9UKIjL89679f43++pMHj+pkQYp3yvI7ztzfsf9+/ni2EeFII8Xv/fWOfl5RySv4AsAG8DOAgABkATwE4oonjWQ+gT9v2bwCW+6+XA/jXBozjdAAnAFhVaRwAzgNwKwAB4BQAjzR4XF8G8GnDvkf4f88sgAP9v7Ndp3EtAHCC/7oXwEv+9Zv6zMqMq6nPzL/vHv91GsAj/nO4AcAl/vYfAPg7//VHAPzAf30JgOvr9LySxvUzAO8w7N+w/33/ep8C8AsAv/ffN/R5TWWL4CQAa6SUa6WUBQDXAbigyWPSuQDANf7rawC8vd4XlFLeB2B3leO4AMD/SI+HAcwQQixo4LiSuADAdVLKvJRyHYA18P7e9RjXVinlE/7rIQDPA1iIJj+zMuNKoiHPzL/vYf9t2v+RAM4CcKO/XX9e9BxvBHC2ENpC3/UdVxIN+98XQuwP4C0ArvbfCzT4eU1lRbAQwEbl/SaU/6LUGwngdiHE40KIy/xt86SUW/3X2wDMa87QEsfRCs/wY75p/hPFddaUcflm+PHwZpMt88y0cQFNfma+m2MlgB0A7oBnfQxIKUuGawfj8j/fC2B2I8YlpaTn9XX/eV0hhMjq4zKMudb8J4DPAHD997PR4Oc1lRVBq3GqlPIEAOcC+KgQ4nT1Q+nZek1P4WqVcfj8N4CDARwHYCuAbzVrIEKIHgC/AvBJKeWg+lkzn5lhXE1/ZlJKR0p5HID94VkdSxs9BhP6uIQQRwH4LLzxvRrALAD/3MgxCSHOB7BDSvl4I6+rM5UVwWYAi5T3+/vbmoKUcrP/eweAm+B9QbaTuen/3tGk4SWNo6nPUEq53f/yugB+hNCV0dBxCSHS8ITttVLKX/ubm/7MTONqlWfmj2UAwD0AXgPPtZIyXDsYl//5dAC7GjSuN/suNimlzAP4KRr/vF4H4G1CiPXw3NdnAfgOGvy8prIieAzAoX70PQMvsPLbZgxECNEthOil1wDOAbDKH88H/N0+AODmZoyvzDh+C+D9fgbFKQD2Ku6QuqP5ZC+E98xoXJf4GRQHAjgUwKN1GoMA8GMAz0spv6181NRnljSuZj8zIcQcIcQM/3UngDfCi1/cA+Ad/m7686Ln+A4Ad/sWViPG9YKizAU8P7z6vOr+d5RSflZKub+Ucgk8GXW3lPI9aPTzqkXEuVV/4EX+X4Lno/x8E8dxELyMjacAPEtjgefbuwvAagB3ApjVgLH8Ep7LoAjP9/jBpHHAy5j4vv/8ngGwrMHj+rl/3af9L8ACZf/P++N6EcC5dRzXqfDcPk8DWOn/nNfsZ1ZmXE19ZgCOAfCkf/1VAL6ofAcehRek/j8AWX97h/9+jf/5QQ0e193+81oF4H8RZhY17H9fGeMZCLOGGvq8uLKYYRimzZnKriGGYRimClgRMAzDtDmsCBiGYdocVgQMwzBtDisChmGYNocVATOlEUI4SmfJlaJCF1ohxIeFEO+vwXXXCyH6JnDcm4QQXxFed9NbJzsOhqmGVOVdGGafZlR6bQWqQkr5g3oOpgpOg1dMdBqAB5o8FqZNYIuAaUv8Gfu/CW+NiEeFEIf4278shPi0//rjwuv3/7QQ4jp/2ywhxG/8bQ8LIY7xt88WQtwuvF73V8MrSKJrvde/xkohxA+FELZhPBf7DdE+Dq8J2Y8A/JUQoinV8Ex7wYqAmep0aq6hi5XP9kopjwbwPXjCV2c5gOOllMcA+LC/7SsAnvS3fQ7A//jbvwTgASnlkfB6SS0GACHEqwBcDOB1vmXiAHiPfiEp5fXwOoiu8sf0jH/tt03m5hmmGtg1xEx1yrmGfqn8vsLw+dMArhVC/AbAb/xtpwL4CwCQUt7tWwLT4C2sc5G//RYhxB5//7MBnAjgMb9tfCeSmwseBmCt/7pbeusMMEzdYUXAtDMy4TXxFngC/q0APi+EOHoC1xAArpFSfrbsTt7ypX0AUkKI5wAs8F1Ffy+lvH8C1/3/7d0hSgVRFIfx769JEB4abOIWRFyA1S6ILkG3YNBqMLgAk+AKBIsICtoF7ZpfMAmmY5h5KI8XLPrA+/3KwFwunHbuPTOcI/2YpSG1bPvb8+H7QpIZYLmqbuh61A+AeeCOvrSTZAMYVjcH4BbY7d9vAqOBMNfAVpKlfm0xycp4IFW1DlzSTaA6pmtMuGoS0F/wRqD/bq4/WY9cVdXoF9KFJI/AB7Aztm8WOE8yoDvVn1bVW5JD4Kzf985XS+Aj4CLJE3APvAJU1XOSA7rpdDN03VX3gZcJsa7RfSzeA04mrEu/wu6jalI/CGS9qobTjkWaNktDktQ4bwSS1DhvBJLUOBOBJDXORCBJjTMRSFLjTASS1DgTgSQ17hMkBmcpsQQfhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(\n",
    "    agent,\n",
    "    max_episodes, # (int): maximum number of training episodes\n",
    "    max_steps, # (int): maximum number of steps per episode\n",
    "    goal_score, # (int): average score to achive over 100 episodes \n",
    "    epsilon_start, # (float): start value of epsilon, for epsilon-greedy action selection\n",
    "    epsilon_end, # (float): minimum value of epsilon\n",
    "    epsilon_decay, # (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    sample_exp_start, # (float): start value fo importance-sampling exponent\n",
    "    sample_exp_end,  # (float): end value fo importance-sampling exponent,\n",
    "    log_every\n",
    "):\n",
    "    scores = [] # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100) # last 100 scores\n",
    "    epsilon = epsilon_start # initialize epsilon\n",
    "    \n",
    "    log_step = 0\n",
    "    \n",
    "    sample_exp = sample_exp_start\n",
    "    sample_exp_step = (sample_exp_end - sample_exp_start) / max_episodes\n",
    "    \n",
    "    for episode in range(1, max_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0] # get the current state\n",
    "        score = 0 # initialize the score\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = agent.act(state, epsilon)\n",
    "            \n",
    "            env_info = env.step(action)[brain_name] # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0] # get the next state\n",
    "            reward = env_info.rewards[0] # get the reward\n",
    "            done = env_info.local_done[0] # see if episode has finished\n",
    "            \n",
    "            if log_every is not None:\n",
    "                log_step = (log_step + 1) % log_every\n",
    "                log = log_step == 0\n",
    "            else:\n",
    "                log = False\n",
    "                \n",
    "            agent.perceive(state, action, reward, next_state, done, sample_exp, log)\n",
    "            \n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        scores_window.append(score) # save most recent score\n",
    "        scores.append(score) # save most recent score\n",
    "        epsilon = max(epsilon_end, epsilon_decay * epsilon) # decrease epsilon\n",
    "        sample_exp += sample_exp_step # increase important-sampling exponent\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)), end=\"\")\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)))\n",
    "        \n",
    "        if np.mean(scores_window) >= goal_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode - 100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def plot_scores(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n",
    "\n",
    "agent = PriorityReplayAgent(\n",
    "    state_size=state_size, \n",
    "    action_size=action_size,\n",
    "    memory_size=int(1e5),\n",
    "    batch_size=64,\n",
    "    priority_exp=0.5,\n",
    "    sort_every=int(1e4),\n",
    "    learn_every=4,\n",
    "    learn_rate=5e-4,\n",
    "    discount_factor=0.99,\n",
    "    soft_update_factor=1e-3,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "scores = train(\n",
    "    agent=agent,  \n",
    "    max_episodes=400, \n",
    "    max_steps=2000, \n",
    "    goal_score=20, \n",
    "    epsilon_start=1.0, \n",
    "    epsilon_end=0.01,\n",
    "    epsilon_decay=0.995,\n",
    "    sample_exp_start=0.3,\n",
    "    sample_exp_end=1,\n",
    "    log_every=None\n",
    ")\n",
    "\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "Important to set epsilon to a non-zero value to avoid the agent getting stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent, eps):\n",
    "    env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations[0] # get the current state\n",
    "    score = 0 # initialize the score\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(state, eps) # select an action\n",
    "        env_info = env.step(action)[brain_name] # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0] # get the next state\n",
    "        reward = env_info.rewards[0] # get the reward\n",
    "        done = env_info.local_done[0] # see if episode has finished\n",
    "        score += reward # update the score\n",
    "        state = next_state # roll over the state to next time step\n",
    "        \n",
    "        if done: # exit loop if episode finished\n",
    "            break\n",
    "    \n",
    "    print(\"Score: {}\".format(score))\n",
    "    \n",
    "test(agent, eps=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
