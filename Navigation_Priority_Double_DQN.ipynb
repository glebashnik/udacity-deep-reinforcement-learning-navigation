{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import heapq\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting global variables, device and random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Seed: 5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "print('Seed:', seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain name: BananaBrain\n",
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "State example: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "State size: 37\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Banana_Linux/Banana.x86_64')\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "print('Brain name:', brain_name)\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "state = env_info.vector_observations[0]\n",
    "print('State example:', state)\n",
    "\n",
    "state_size = len(state)\n",
    "print('State size:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of segments for importance sampling based on ranking, higher `priority_exp` skews segments more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>priority exponent</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment boundaries</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "priority exponent   0.00   0.25   0.50   0.75  1.00\n",
       "segment boundaries                                 \n",
       "0                    0.0  0.000  0.000  0.000  0.00\n",
       "1                    0.2  0.134  0.089  0.060  0.04\n",
       "2                    0.4  0.318  0.253  0.201  0.16\n",
       "3                    0.6  0.528  0.465  0.409  0.36\n",
       "4                    0.8  0.757  0.716  0.677  0.64\n",
       "5                    1.0  1.000  1.000  1.000  1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_priority_segments(num_segments, priority_exp):\n",
    "    return [(i / num_segments) ** (priority_exp + 1) for i in range(num_segments + 1)]\n",
    " \n",
    "def demo_compute_priority_segments():\n",
    "    priority_exps = [0, 0.25, 0.5, 0.75, 1]\n",
    "    segments = {e: compute_priority_segments(5, e) for e in priority_exps}\n",
    "    \n",
    "    df = pd.DataFrame(segments)\n",
    "    df.columns.name = 'priority exponent'\n",
    "    df.index.name = 'segment boundaries'\n",
    "    pd.set_option('precision', 3)\n",
    "    display(df)\n",
    "        \n",
    "demo_compute_priority_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes importance sampling probabilities. Higher ranked items have higher sampling probability. Probabilities of all ranks should sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>priority exponent</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "priority exponent  0.00   0.25   0.50   0.75   0.99\n",
       "rank                                               \n",
       "1                  0.01  0.024  0.056  0.116  0.212\n",
       "20                 0.01  0.012  0.012  0.012  0.011\n",
       "40                 0.01  0.010  0.009  0.007  0.006\n",
       "60                 0.01  0.009  0.007  0.005  0.004\n",
       "80                 0.01  0.008  0.006  0.004  0.003\n",
       "100                0.01  0.008  0.006  0.004  0.002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_rank_probs(ranks, memory_size, priority_exp):\n",
    "    return (1 - priority_exp) / ranks**priority_exp / (memory_size**(1 - priority_exp) - 1)\n",
    "\n",
    "def demo_compute_rank_probs():\n",
    "    ranks = np.array([1, 20, 40, 60, 80, 100])\n",
    "    priority_exps = [0, 0.25, 0.5, 0.75, 0.99]\n",
    "    rank_probs = {e: compute_rank_probs(ranks, 100, e) for e in priority_exps}\n",
    "    \n",
    "    df = pd.DataFrame(rank_probs, index=ranks)\n",
    "    df.columns.name = 'priority exponent'\n",
    "    df.index.name = 'rank'\n",
    "    pd.set_option('precision', 3)\n",
    "    display(df)\n",
    "\n",
    "demo_compute_rank_probs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameter update weights based on importance sampling probabilities. Higher probability should be assigned lower weight to avoid skewed distribution learned by the qnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sample exponent</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sample exponent  0.00   0.25   0.50   0.75   1.00\n",
       "rank                                             \n",
       "1                 1.0  0.562  0.316  0.178  0.100\n",
       "20                1.0  0.818  0.669  0.547  0.447\n",
       "40                1.0  0.892  0.795  0.709  0.632\n",
       "60                1.0  0.938  0.880  0.826  0.775\n",
       "80                1.0  0.972  0.946  0.920  0.894\n",
       "100               1.0  1.000  1.000  1.000  1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_sample_weights(sample_probs, memory_size, priority_exp, sample_exp):\n",
    "    min_sample_prob = compute_rank_probs(memory_size, memory_size, priority_exp)\n",
    "    max_sample_weight = (memory_size * min_sample_prob)**(-sample_exp)\n",
    "    sample_weights = (memory_size * sample_probs)**(-sample_exp) / max_sample_weight\n",
    "    return sample_weights\n",
    "    \n",
    "def demo_compute_sample_weights():\n",
    "    memory_size = 100\n",
    "    priority_exp = 0.5\n",
    "    ranks = np.array([1, 20, 40, 60, 80, 100])\n",
    "    sample_exps = [0, 0.25, 0.5, 0.75, 1]\n",
    "    sample_probs = compute_rank_probs(ranks, memory_size, priority_exp)\n",
    "    sample_weights = {e: compute_sample_weights(sample_probs, memory_size, priority_exp, e) for e in sample_exps}\n",
    "\n",
    "    df = pd.DataFrame(sample_weights, index=ranks)\n",
    "    df.index.name = 'rank'\n",
    "    df.columns.name = 'sample exponent'\n",
    "    pd.set_option('precision', 3)\n",
    "    display(df)\n",
    "\n",
    "demo_compute_sample_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of priority replay memory, which uses binary heap to keep experiences in approximately sorted order by TD-error. Importance sampling is implemented using unevenly sized segments, i.e. segment size decreases from top to bottom of the heap. Number of segments is equal to the batch size. One experience is sampled per segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>997</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>988</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>908</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>866</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>696</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>686</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   error  weight\n",
       "0    997   0.416\n",
       "1    988   0.514\n",
       "2    978   0.562\n",
       "3    908   0.707\n",
       "4    866   0.740\n",
       "5    696   0.828\n",
       "6    686   0.832\n",
       "7     39   0.884\n",
       "8     27   0.924\n",
       "9      9   0.977"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PriorityReplayMemory:\n",
    "    def __init__(self, \n",
    "                 memory_size, # (int) max size of memory\n",
    "                 batch_size, # (int) number of items to sample in one batch\n",
    "                 priority_exp, # (float) priority exponent controls the uniformness of sampling\n",
    "                 sort_freq): # (int) number of items added before the heap is resorted\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.priority_exp = priority_exp\n",
    "        self.sort_freq = sort_freq\n",
    "        \n",
    "        self.memory = [] # min heap to store experiences\n",
    "        self.step = 0\n",
    "        \n",
    "        self.segments = compute_priority_segments(batch_size, priority_exp)\n",
    "        self.counter = itertools.count() \n",
    "    \n",
    "    def add(self, experience, error=None):\n",
    "        if error is None: # new expereinces get maximal priority\n",
    "            if len(self.memory) > 0:\n",
    "                priority = self.memory[0][0]\n",
    "            else:\n",
    "                priority = -10 # shouldn't matter\n",
    "        else:\n",
    "            priority = -error # min heap stores min priority first\n",
    "\n",
    "        count = next(self.counter)\n",
    "        heapq.heappush(self.memory, (priority, count, experience))\n",
    "        \n",
    "        # Remove last experience\n",
    "        if len(self.memory) > self.memory_size:\n",
    "            self.memory.pop()\n",
    "            \n",
    "        # Resort the heap every sort_freq times: O(n*log(n))\n",
    "        self.step = (self.step + 1) % self.sort_freq\n",
    "        \n",
    "        if self.step == 0:\n",
    "            self.memory.sort(key=lambda x: x[0])\n",
    "            \n",
    "    def sample(self, sample_exp):\n",
    "        size = len(self.memory)\n",
    "\n",
    "        # Scale segements to the number of experiences\n",
    "        segments = [(math.ceil(start * (size - 1)), math.floor(end * (size - 1)))\n",
    "                    for start, end in zip(self.segments[:-1], self.segments[1:])]\n",
    "        \n",
    "        # Check if the first (smallest) segment contains more than one experience\n",
    "        if segments[0][0] < segments[0][1]:\n",
    "            indexes = [random.randint(start, end) for start, end in segments]\n",
    "        else: # Ignore segments, do uniform sampling\n",
    "            indexes = random.sample(range(size), self.batch_size)\n",
    "            \n",
    "        # Select experiences\n",
    "        experiences = [self.memory[i][2] for i in indexes]\n",
    "        \n",
    "        # Compute importance-sampling weights\n",
    "        ranks = np.array(indexes) + 1\n",
    "        probs = compute_rank_probs(ranks, self.memory_size, self.priority_exp)\n",
    "        weights = compute_sample_weights(probs, self.memory_size, self.priority_exp, sample_exp)\n",
    "            \n",
    "        # Remove sampled experiences\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del self.memory[index]\n",
    "            \n",
    "        # O(n)\n",
    "        # heapq.heapify(self.memory)\n",
    "        \n",
    "        return experiences, weights\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "def demo_priority_replay_memory():\n",
    "    memory = PriorityReplayMemory(memory_size=100, batch_size=10, priority_exp=0.5, sort_freq=10)\n",
    "    \n",
    "    for i in range(1000):\n",
    "        memory.add(i, i)\n",
    "\n",
    "    exps, probs = memory.sample(0.5)\n",
    "    df = pd.DataFrame({'error': exps, 'weight': probs})\n",
    "    pd.set_option('precision', 3)\n",
    "    return df\n",
    "    \n",
    "demo_priority_replay_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-network\n",
    "\n",
    "Dense neural network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, fc1_size, fc2_size):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "        \"\"\"\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, fc1_size)\n",
    "        self.bc1 = nn.BatchNorm1d(fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        self.bc2 = nn.BatchNorm1d(fc2_size)\n",
    "        self.fc3 = nn.Linear(fc2_size, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.bc1(self.fc1(state)))\n",
    "        x = F.relu(self.bc2(self.fc2(x)))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent\n",
    "\n",
    "Implements prioritized experience replay, fixed Q-targets and Double DQN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple('Experience', 'state action reward next_state done')\n",
    "\n",
    "def get_fields_from_experiences(experiences):\n",
    "    states = torch.from_numpy(np.vstack([e.state for e in experiences])).float().to(device)\n",
    "    actions = torch.from_numpy(np.vstack([e.action for e in experiences])).long().to(device)\n",
    "    rewards = torch.from_numpy(np.vstack([e.reward for e in experiences])).float().to(device)\n",
    "    next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences])).float().to(device)\n",
    "    dones = torch.from_numpy(np.vstack([e.done for e in experiences]).astype(np.uint8)).float().to(device)\n",
    "    return states, actions, rewards, next_states, dones\n",
    "\n",
    "class PriorityDoubleDQNAgent:\n",
    "    def __init__(self,\n",
    "                 state_size, # (int) number of dimensions in a state vector\n",
    "                 action_size, # (int) number of actions the agent can take\n",
    "                 replay_memory, # (object) experience replay memory\n",
    "                 replay_start, # (int) number of experiences to collect before start learning\n",
    "                 online_qnet, # (object) online Q-network used fo taking actions\n",
    "                 target_qnet, # (object) target Q-network used for computing TD-error (Q-targets and Double DQN)\n",
    "                 learn_freq, # (int) steps between learning\n",
    "                 learn_rate, # (float) how much to learn in each parameter update of online Q-network\n",
    "                 discount_factor, # (float) discounts the reward from consequent states\n",
    "                 target_update_freq, # (int) number of parameter updates before updated the target Q-network\n",
    "                 soft_update_factor # (float) how much to update the target from online Q-network\n",
    "                ):\n",
    "        self.action_size = action_size\n",
    "        self.replay_memory = replay_memory\n",
    "        self.replay_start = replay_start\n",
    "        self.learn_freq = learn_freq\n",
    "        self.discount_factor = discount_factor\n",
    "        self.target_update_freq = target_update_freq\n",
    "        self.soft_update_factor = soft_update_factor\n",
    "        \n",
    "        self.online_qnet = online_qnet.to(device)\n",
    "        self.target_qnet = target_qnet.to(device)\n",
    "        self.optimizer = optim.Adam(self.online_qnet.parameters(), lr=learn_rate)\n",
    "\n",
    "        self.learn_step = 0\n",
    "        self.target_update_step = 0\n",
    "\n",
    "    def perceive(self, state, action, reward, next_state, done, sample_exp):\n",
    "        experience = Experience(state, action, reward, next_state, done)\n",
    "        self.replay_memory.add(experience)\n",
    "\n",
    "        self.learn_step = (self.learn_step + 1) % self.learn_freq\n",
    "\n",
    "        if self.learn_step == 0 and len(self.replay_memory) >= self.replay_start:\n",
    "            self.learn(sample_exp)\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "\n",
    "        self.online_qnet.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_values = self.online_qnet(state)\n",
    "\n",
    "        self.online_qnet.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > epsilon:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, sample_exp):\n",
    "        experiences, sample_weights = self.replay_memory.sample(sample_exp)\n",
    "        states, actions, rewards, next_states, dones = get_fields_from_experiences(experiences)\n",
    "\n",
    "        # Get actions for next states from online Q-network (Double DQN)\n",
    "        expected_next_actions = self.online_qnet(next_states).detach().max(1)[1].unsqueeze(1)\n",
    "        # Get Q values for next actions from target Q-network\n",
    "        Q_next_targets = self.target_qnet(next_states).detach().gather(1, expected_next_actions)\n",
    "        # Compute Q targets for current states\n",
    "        Q_targets = rewards + self.discount_factor * Q_next_targets * (1 - dones)\n",
    "        # Get expected Q values from online model\n",
    "        Q_expected = self.online_qnet(states).gather(1, actions)\n",
    "        # Compute TD errors\n",
    "        td_errors = Q_targets - Q_expected\n",
    "\n",
    "        # Re-add sampled experiences with new priorities\n",
    "        priorities = td_errors.detach().cpu().abs().squeeze().numpy()\n",
    "\n",
    "        for experience, priority in zip(experiences, priorities):\n",
    "            self.replay_memory.add(experience, priority)\n",
    "\n",
    "        # Compute loss with importance-sampling weights\n",
    "        sample_weights = torch.from_numpy(sample_weights).float().unsqueeze(1).to(device)\n",
    "        loss = (sample_weights * td_errors ** 2).mean()\n",
    "\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Soft update of the target model every target_update_freq times\n",
    "        self.target_update_step = (self.target_update_step + 1) % self.target_update_freq\n",
    "\n",
    "        if self.target_update_step == 0:\n",
    "            for target_param, online_param in zip(self.target_qnet.parameters(), self.online_qnet.parameters()):\n",
    "                target_param.data.copy_(\n",
    "                    self.soft_update_factor * online_param.data + (1.0 - self.soft_update_factor) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.27\n",
      "Episode 200\tAverage Score: 2.21\n",
      "Episode 300\tAverage Score: 6.18\n",
      "Episode 400\tAverage Score: 10.33\n",
      "Episode 500\tAverage Score: 11.92\n",
      "Episode 586\tAverage Score: 13.04\n",
      "Environment solved in 486 episodes!\tAverage Score: 13.04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(\n",
    "    agent,\n",
    "    max_episodes, # (int): maximum number of training episodes\n",
    "    max_steps, # (int): maximum number of steps per episode\n",
    "    goal_score, # (int): average score to achive over 100 episodes \n",
    "    epsilon_start, # (float): start value of epsilon, for epsilon-greedy action selection\n",
    "    epsilon_end, # (float): minimum value of epsilon\n",
    "    epsilon_decay, # (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    sample_exp_start, # (float): start value fo importance-sampling exponent\n",
    "    sample_exp_end,  # (float): end value fo importance-sampling exponent,\n",
    "    model_path # file path to save the Q-network parameters\n",
    "):\n",
    "    scores = [] # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100) # last 100 scores\n",
    "    epsilon = epsilon_start # initialize epsilon\n",
    "    \n",
    "    sample_exp = sample_exp_start\n",
    "    sample_exp_step = (sample_exp_end - sample_exp_start) / max_episodes\n",
    "    \n",
    "    for episode in range(1, max_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0] # get the current state\n",
    "        score = 0 # initialize the score\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = agent.act(state, epsilon)\n",
    "            \n",
    "            env_info = env.step(action)[brain_name] # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0] # get the next state\n",
    "            reward = env_info.rewards[0] # get the reward\n",
    "            done = env_info.local_done[0] # see if episode has finished\n",
    "                \n",
    "            agent.perceive(state, action, reward, next_state, done, sample_exp)\n",
    "            \n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        scores_window.append(score) # save most recent score\n",
    "        scores.append(score) # save most recent score\n",
    "        epsilon = max(epsilon_end, epsilon_decay * epsilon) # decrease epsilon\n",
    "        sample_exp += sample_exp_step # increase important-sampling exponent\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)), end=\"\")\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window)))\n",
    "        \n",
    "        if np.mean(scores_window) >= goal_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode - 100, np.mean(scores_window)))\n",
    "            torch.save(agent.online_qnet.state_dict(), model_path)\n",
    "            break\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def plot_scores(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n",
    "\n",
    "replay_memory = PriorityReplayMemory(\n",
    "    memory_size=int(1e5),\n",
    "    batch_size=64,\n",
    "    priority_exp=0.5,\n",
    "    sort_freq=int(1e4),\n",
    ")\n",
    "\n",
    "online_qnet = QNet(state_size, action_size, 64, 64)\n",
    "target_qnet = QNet(state_size, action_size, 64, 64)\n",
    "\n",
    "agent = PriorityDoubleDQNAgent(\n",
    "    state_size=state_size, \n",
    "    action_size=action_size,\n",
    "    replay_memory = replay_memory,\n",
    "    replay_start=500,\n",
    "    online_qnet=online_qnet,\n",
    "    target_qnet= target_qnet,\n",
    "    learn_freq=4,\n",
    "    learn_rate=5e-4,\n",
    "    discount_factor=0.99,\n",
    "    target_update_freq=1,\n",
    "    soft_update_factor=1e-3\n",
    ")\n",
    "\n",
    "scores = train(\n",
    "    agent=agent,  \n",
    "    max_episodes=700, \n",
    "    max_steps=1000, \n",
    "    goal_score=13, \n",
    "    epsilon_start=1.0, \n",
    "    epsilon_end=0.01,\n",
    "    epsilon_decay=0.995,\n",
    "    sample_exp_start=0,\n",
    "    sample_exp_end=0.5,\n",
    "    model_path='models/dqn.pth'\n",
    ")\n",
    "\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the agent in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 18.0\n"
     ]
    }
   ],
   "source": [
    "def test(agent, epsilon=0.01):\n",
    "    env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations[0] # get the current state\n",
    "    score = 0 # initialize the score\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(state, epsilon) # select an action\n",
    "        env_info = env.step(action)[brain_name] # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0] # get the next state\n",
    "        reward = env_info.rewards[0] # get the reward\n",
    "        done = env_info.local_done[0] # see if episode has finished\n",
    "        score += reward # update the score\n",
    "        state = next_state # roll over the state to next time step\n",
    "        \n",
    "        if done: # exit loop if episode finished\n",
    "            break\n",
    "    \n",
    "    print(\"Score: {}\".format(score))\n",
    "    \n",
    "test(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
